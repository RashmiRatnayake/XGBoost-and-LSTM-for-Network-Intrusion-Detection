{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Data columns (total 42 columns):\n",
      "duration                       125973 non-null int64\n",
      "protocol_type                  125973 non-null object\n",
      "service                        125973 non-null object\n",
      "flag                           125973 non-null object\n",
      "src_bytes                      125973 non-null int64\n",
      "dst_bytes                      125973 non-null int64\n",
      "land                           125973 non-null int64\n",
      "wrong_fragment                 125973 non-null int64\n",
      "urgent                         125973 non-null int64\n",
      "hot                            125973 non-null int64\n",
      "num_failed_logins              125973 non-null int64\n",
      "logged_in                      125973 non-null int64\n",
      "num_compromised                125973 non-null int64\n",
      "root_shell                     125973 non-null int64\n",
      "su_attempted                   125973 non-null int64\n",
      "num_root                       125973 non-null int64\n",
      "num_file_creations             125973 non-null int64\n",
      "num_shells                     125973 non-null int64\n",
      "num_access_files               125973 non-null int64\n",
      "num_outbound_cmds              125973 non-null int64\n",
      "is_host_login                  125973 non-null int64\n",
      "is_guest_login                 125973 non-null int64\n",
      "count                          125973 non-null int64\n",
      "srv_count                      125973 non-null int64\n",
      "serror_rate                    125973 non-null float64\n",
      "srv_serror_rate                125973 non-null float64\n",
      "rerror_rate                    125973 non-null float64\n",
      "srv_rerror_rate                125973 non-null float64\n",
      "same_srv_rate                  125973 non-null float64\n",
      "diff_srv_rate                  125973 non-null float64\n",
      "srv_diff_host_rate             125973 non-null float64\n",
      "dst_host_count                 125973 non-null int64\n",
      "dst_host_srv_count             125973 non-null int64\n",
      "dst_host_same_srv_rate         125973 non-null float64\n",
      "dst_host_diff_srv_rate         125973 non-null float64\n",
      "dst_host_same_src_port_rate    125973 non-null float64\n",
      "dst_host_srv_diff_host_rate    125973 non-null float64\n",
      "dst_host_serror_rate           125973 non-null float64\n",
      "dst_host_srv_serror_rate       125973 non-null float64\n",
      "dst_host_rerror_rate           125973 non-null float64\n",
      "dst_host_srv_rerror_rate       125973 non-null float64\n",
      "class                          125973 non-null object\n",
      "dtypes: float64(15), int64(23), object(4)\n",
      "memory usage: 40.4+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22543 entries, 0 to 22542\n",
      "Data columns (total 42 columns):\n",
      "duration                       22543 non-null int64\n",
      "protocol_type                  22543 non-null object\n",
      "service                        22543 non-null object\n",
      "flag                           22543 non-null object\n",
      "src_bytes                      22543 non-null int64\n",
      "dst_bytes                      22543 non-null int64\n",
      "land                           22543 non-null int64\n",
      "wrong_fragment                 22543 non-null int64\n",
      "urgent                         22543 non-null int64\n",
      "hot                            22543 non-null int64\n",
      "num_failed_logins              22543 non-null int64\n",
      "logged_in                      22543 non-null int64\n",
      "num_compromised                22543 non-null int64\n",
      "root_shell                     22543 non-null int64\n",
      "su_attempted                   22543 non-null int64\n",
      "num_root                       22543 non-null int64\n",
      "num_file_creations             22543 non-null int64\n",
      "num_shells                     22543 non-null int64\n",
      "num_access_files               22543 non-null int64\n",
      "num_outbound_cmds              22543 non-null int64\n",
      "is_host_login                  22543 non-null int64\n",
      "is_guest_login                 22543 non-null int64\n",
      "count                          22543 non-null int64\n",
      "srv_count                      22543 non-null int64\n",
      "serror_rate                    22543 non-null float64\n",
      "srv_serror_rate                22543 non-null float64\n",
      "rerror_rate                    22543 non-null float64\n",
      "srv_rerror_rate                22543 non-null float64\n",
      "same_srv_rate                  22543 non-null float64\n",
      "diff_srv_rate                  22543 non-null float64\n",
      "srv_diff_host_rate             22543 non-null float64\n",
      "dst_host_count                 22543 non-null int64\n",
      "dst_host_srv_count             22543 non-null int64\n",
      "dst_host_same_srv_rate         22543 non-null float64\n",
      "dst_host_diff_srv_rate         22543 non-null float64\n",
      "dst_host_same_src_port_rate    22543 non-null float64\n",
      "dst_host_srv_diff_host_rate    22543 non-null float64\n",
      "dst_host_serror_rate           22543 non-null float64\n",
      "dst_host_srv_serror_rate       22543 non-null float64\n",
      "dst_host_rerror_rate           22543 non-null float64\n",
      "dst_host_srv_rerror_rate       22543 non-null float64\n",
      "class                          22543 non-null object\n",
      "dtypes: float64(15), int64(23), object(4)\n",
      "memory usage: 7.2+ MB\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding, BatchNormalization\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "from keras import optimizers\n",
    "import datetime\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(\n",
    "        target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    # Regression\n",
    "    return df[result].values.astype(np.float32), df[[target]].values.astype(np.float32)\n",
    "\n",
    "\n",
    "traindata = pd.read_csv('KDDTrain+.csv', header=None)\n",
    "testdata = pd.read_csv('KDDTest+.csv', header=None)\n",
    "\n",
    "\n",
    "columns = [\n",
    "    'duration',\n",
    "    'protocol_type',\n",
    "    'service',\n",
    "    'flag',\n",
    "    'src_bytes',\n",
    "    'dst_bytes',\n",
    "    'land',\n",
    "    'wrong_fragment',\n",
    "    'urgent',\n",
    "    'hot',\n",
    "    'num_failed_logins',\n",
    "    'logged_in',\n",
    "    'num_compromised',\n",
    "    'root_shell',\n",
    "    'su_attempted',\n",
    "    'num_root',\n",
    "    'num_file_creations',\n",
    "    'num_shells',\n",
    "    'num_access_files',\n",
    "    'num_outbound_cmds',\n",
    "    'is_host_login',\n",
    "    'is_guest_login',\n",
    "    'count',\n",
    "    'srv_count',\n",
    "    'serror_rate',\n",
    "    'srv_serror_rate',\n",
    "    'rerror_rate',\n",
    "    'srv_rerror_rate',\n",
    "    'same_srv_rate',\n",
    "    'diff_srv_rate',\n",
    "    'srv_diff_host_rate',\n",
    "    'dst_host_count',\n",
    "    'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate',\n",
    "    'dst_host_diff_srv_rate',\n",
    "    'dst_host_same_src_port_rate',\n",
    "    'dst_host_srv_diff_host_rate',\n",
    "    'dst_host_serror_rate',\n",
    "    'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate',\n",
    "    'dst_host_srv_rerror_rate',\n",
    "    'class',\n",
    "    'difficulty_level'\n",
    "]\n",
    "traindata.columns=columns\n",
    "testdata.columns=columns\n",
    "\n",
    "del traindata[\"difficulty_level\"]\n",
    "del testdata[\"difficulty_level\"]\n",
    "traindata.info()\n",
    "testdata.info()\n",
    "trainlen=traindata.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        duration protocol_type     service  flag  src_bytes  dst_bytes  land  \\\n",
      "0              0           tcp    ftp_data    SF        491          0     0   \n",
      "1              0           udp       other    SF        146          0     0   \n",
      "2              0           tcp     private    S0          0          0     0   \n",
      "3              0           tcp        http    SF        232       8153     0   \n",
      "4              0           tcp        http    SF        199        420     0   \n",
      "5              0           tcp     private   REJ          0          0     0   \n",
      "6              0           tcp     private    S0          0          0     0   \n",
      "7              0           tcp     private    S0          0          0     0   \n",
      "8              0           tcp  remote_job    S0          0          0     0   \n",
      "9              0           tcp     private    S0          0          0     0   \n",
      "10             0           tcp     private   REJ          0          0     0   \n",
      "11             0           tcp     private    S0          0          0     0   \n",
      "12             0           tcp        http    SF        287       2251     0   \n",
      "13             0           tcp    ftp_data    SF        334          0     0   \n",
      "14             0           tcp        name    S0          0          0     0   \n",
      "15             0           tcp  netbios_ns    S0          0          0     0   \n",
      "16             0           tcp        http    SF        300      13788     0   \n",
      "17             0          icmp       eco_i    SF         18          0     0   \n",
      "18             0           tcp        http    SF        233        616     0   \n",
      "19             0           tcp        http    SF        343       1178     0   \n",
      "20             0           tcp         mtp    S0          0          0     0   \n",
      "21             0           tcp     private    S0          0          0     0   \n",
      "22             0           tcp        http    SF        253      11905     0   \n",
      "23          5607           udp       other    SF        147        105     0   \n",
      "24             0           tcp         mtp    S0          0          0     0   \n",
      "25           507           tcp      telnet    SF        437      14421     0   \n",
      "26             0           tcp     private    S0          0          0     0   \n",
      "27             0           tcp        http    SF        227       6588     0   \n",
      "28             0           tcp        http    SF        215      10499     0   \n",
      "29             0           tcp        http    SF        241       1400     0   \n",
      "...          ...           ...         ...   ...        ...        ...   ...   \n",
      "148486         0           udp       other    SF        115          0     0   \n",
      "148487         0           tcp        http    S0          0          0     0   \n",
      "148488         0           tcp        http    SF        322        396     0   \n",
      "148489      7498           tcp      telnet    SF          0         44     0   \n",
      "148490         0           tcp        http    SF        295        757     0   \n",
      "148491      8209           tcp      telnet    SF          0         15     0   \n",
      "148492         0           tcp     private   REJ          0          0     0   \n",
      "148493         0           udp     private    SF          1          1     0   \n",
      "148494         0           tcp        http    SF      54540       8314     0   \n",
      "148495         0           tcp        http    SF        289       9522     0   \n",
      "148496        15           tcp         ftp    SF         45        214     0   \n",
      "148497      2064           tcp        http  RSTR      55744          0     0   \n",
      "148498         0           tcp        http    SF        169       4997     0   \n",
      "148499         0           tcp        http    SF        236      16257     0   \n",
      "148500         0          icmp       ecr_i    SF       1032          0     0   \n",
      "148501         0           tcp      finger    SF          9        139     0   \n",
      "148502         0           tcp     private    S0          0          0     0   \n",
      "148503         0           tcp     private    S0          0          0     0   \n",
      "148504         0           tcp        http    SF        264      14839     0   \n",
      "148505         0           tcp        http    SF        274       1623     0   \n",
      "148506         0           tcp     private   REJ          0          0     0   \n",
      "148507         0           tcp        http    SF        280       6087     0   \n",
      "148508         0           tcp    iso_tsap   REJ          0          0     0   \n",
      "148509         1           tcp        smtp    SF       2599        293     0   \n",
      "148510         0          icmp       ecr_i    SF       1032          0     0   \n",
      "148511         0           tcp        smtp    SF        794        333     0   \n",
      "148512         0           tcp        http    SF        317        938     0   \n",
      "148513         0           tcp        http    SF      54540       8314     0   \n",
      "148514         0           udp    domain_u    SF         42         42     0   \n",
      "148515         0           tcp      sunrpc   REJ          0          0     0   \n",
      "\n",
      "        wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
      "0                    0       0    0  ...                  25   \n",
      "1                    0       0    0  ...                   1   \n",
      "2                    0       0    0  ...                  26   \n",
      "3                    0       0    0  ...                 255   \n",
      "4                    0       0    0  ...                 255   \n",
      "5                    0       0    0  ...                  19   \n",
      "6                    0       0    0  ...                   9   \n",
      "7                    0       0    0  ...                  15   \n",
      "8                    0       0    0  ...                  23   \n",
      "9                    0       0    0  ...                  13   \n",
      "10                   0       0    0  ...                  12   \n",
      "11                   0       0    0  ...                  13   \n",
      "12                   0       0    0  ...                 219   \n",
      "13                   0       0    0  ...                  20   \n",
      "14                   0       0    0  ...                   1   \n",
      "15                   0       0    0  ...                   2   \n",
      "16                   0       0    0  ...                 255   \n",
      "17                   0       0    0  ...                  16   \n",
      "18                   0       0    0  ...                 255   \n",
      "19                   0       0    0  ...                 255   \n",
      "20                   0       0    0  ...                  23   \n",
      "21                   0       0    0  ...                  17   \n",
      "22                   0       0    0  ...                 255   \n",
      "23                   0       0    0  ...                   1   \n",
      "24                   0       0    0  ...                   2   \n",
      "25                   0       0    0  ...                  25   \n",
      "26                   0       0    0  ...                  13   \n",
      "27                   0       0    0  ...                 255   \n",
      "28                   0       0    0  ...                 255   \n",
      "29                   0       0    0  ...                 255   \n",
      "...                ...     ...  ...  ...                 ...   \n",
      "148486               0       0    0  ...                  22   \n",
      "148487               0       0    0  ...                 255   \n",
      "148488               0       0    0  ...                 241   \n",
      "148489               0       0    0  ...                 192   \n",
      "148490               0       0    0  ...                 255   \n",
      "148491               0       0    0  ...                   9   \n",
      "148492               0       0    0  ...                   1   \n",
      "148493               0       0    0  ...                   1   \n",
      "148494               0       0    2  ...                 255   \n",
      "148495               0       0    0  ...                 255   \n",
      "148496               0       0    0  ...                   4   \n",
      "148497               0       0    0  ...                 244   \n",
      "148498               0       0    0  ...                 255   \n",
      "148499               0       0    0  ...                 255   \n",
      "148500               0       0    0  ...                 255   \n",
      "148501               0       0    0  ...                   4   \n",
      "148502               0       0    0  ...                   7   \n",
      "148503               0       0    0  ...                  12   \n",
      "148504               0       0    0  ...                 255   \n",
      "148505               0       0    0  ...                 255   \n",
      "148506               0       0    0  ...                  10   \n",
      "148507               0       0    0  ...                 255   \n",
      "148508               0       0    0  ...                  18   \n",
      "148509               0       0    0  ...                 186   \n",
      "148510               0       0    0  ...                 255   \n",
      "148511               0       0    0  ...                 141   \n",
      "148512               0       0    0  ...                 255   \n",
      "148513               0       0    2  ...                 255   \n",
      "148514               0       0    0  ...                 252   \n",
      "148515               0       0    0  ...                  21   \n",
      "\n",
      "        dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
      "0                         0.17                    0.03   \n",
      "1                         0.00                    0.60   \n",
      "2                         0.10                    0.05   \n",
      "3                         1.00                    0.00   \n",
      "4                         1.00                    0.00   \n",
      "5                         0.07                    0.07   \n",
      "6                         0.04                    0.05   \n",
      "7                         0.06                    0.07   \n",
      "8                         0.09                    0.05   \n",
      "9                         0.05                    0.06   \n",
      "10                        0.05                    0.07   \n",
      "11                        0.05                    0.07   \n",
      "12                        1.00                    0.00   \n",
      "13                        1.00                    0.00   \n",
      "14                        0.00                    0.07   \n",
      "15                        0.01                    0.06   \n",
      "16                        1.00                    0.00   \n",
      "17                        1.00                    0.00   \n",
      "18                        1.00                    0.00   \n",
      "19                        1.00                    0.00   \n",
      "20                        0.09                    0.05   \n",
      "21                        0.07                    0.06   \n",
      "22                        1.00                    0.00   \n",
      "23                        0.00                    0.85   \n",
      "24                        0.01                    0.06   \n",
      "25                        0.10                    0.05   \n",
      "26                        0.05                    0.07   \n",
      "27                        1.00                    0.00   \n",
      "28                        1.00                    0.00   \n",
      "29                        1.00                    0.00   \n",
      "...                        ...                     ...   \n",
      "148486                    0.09                    0.04   \n",
      "148487                    1.00                    0.00   \n",
      "148488                    1.00                    0.00   \n",
      "148489                    0.75                    0.02   \n",
      "148490                    1.00                    0.00   \n",
      "148491                    0.04                    0.85   \n",
      "148492                    0.00                    0.14   \n",
      "148493                    0.00                    0.54   \n",
      "148494                    1.00                    0.00   \n",
      "148495                    1.00                    0.00   \n",
      "148496                    0.02                    0.03   \n",
      "148497                    0.96                    0.01   \n",
      "148498                    1.00                    0.00   \n",
      "148499                    1.00                    0.00   \n",
      "148500                    1.00                    0.00   \n",
      "148501                    0.04                    0.03   \n",
      "148502                    0.03                    0.08   \n",
      "148503                    0.05                    0.07   \n",
      "148504                    1.00                    0.00   \n",
      "148505                    1.00                    0.00   \n",
      "148506                    0.04                    0.07   \n",
      "148507                    1.00                    0.00   \n",
      "148508                    0.07                    0.05   \n",
      "148509                    0.73                    0.13   \n",
      "148510                    1.00                    0.00   \n",
      "148511                    0.72                    0.06   \n",
      "148512                    1.00                    0.00   \n",
      "148513                    1.00                    0.00   \n",
      "148514                    0.99                    0.01   \n",
      "148515                    0.08                    0.03   \n",
      "\n",
      "        dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
      "0                              0.17                         0.00   \n",
      "1                              0.88                         0.00   \n",
      "2                              0.00                         0.00   \n",
      "3                              0.03                         0.04   \n",
      "4                              0.00                         0.00   \n",
      "5                              0.00                         0.00   \n",
      "6                              0.00                         0.00   \n",
      "7                              0.00                         0.00   \n",
      "8                              0.00                         0.00   \n",
      "9                              0.00                         0.00   \n",
      "10                             0.00                         0.00   \n",
      "11                             0.00                         0.00   \n",
      "12                             0.12                         0.03   \n",
      "13                             1.00                         0.20   \n",
      "14                             0.00                         0.00   \n",
      "15                             0.00                         0.00   \n",
      "16                             0.01                         0.02   \n",
      "17                             1.00                         1.00   \n",
      "18                             0.02                         0.03   \n",
      "19                             0.01                         0.04   \n",
      "20                             0.00                         0.00   \n",
      "21                             0.00                         0.00   \n",
      "22                             0.01                         0.02   \n",
      "23                             1.00                         0.00   \n",
      "24                             0.00                         0.00   \n",
      "25                             0.00                         0.00   \n",
      "26                             0.00                         0.00   \n",
      "27                             0.02                         0.14   \n",
      "28                             0.00                         0.00   \n",
      "29                             0.00                         0.00   \n",
      "...                             ...                          ...   \n",
      "148486                         0.14                         0.00   \n",
      "148487                         0.00                         0.00   \n",
      "148488                         0.03                         0.03   \n",
      "148489                         0.00                         0.00   \n",
      "148490                         0.00                         0.00   \n",
      "148491                         0.00                         0.00   \n",
      "148492                         0.00                         0.00   \n",
      "148493                         0.97                         0.00   \n",
      "148494                         0.00                         0.00   \n",
      "148495                         0.01                         0.03   \n",
      "148496                         0.00                         0.00   \n",
      "148497                         0.00                         0.00   \n",
      "148498                         0.02                         0.02   \n",
      "148499                         0.25                         0.06   \n",
      "148500                         1.00                         0.00   \n",
      "148501                         0.01                         0.00   \n",
      "148502                         0.00                         0.00   \n",
      "148503                         0.00                         0.00   \n",
      "148504                         0.00                         0.00   \n",
      "148505                         0.01                         0.04   \n",
      "148506                         0.00                         0.00   \n",
      "148507                         0.20                         0.04   \n",
      "148508                         0.00                         0.00   \n",
      "148509                         0.00                         0.00   \n",
      "148510                         1.00                         0.00   \n",
      "148511                         0.01                         0.01   \n",
      "148512                         0.01                         0.01   \n",
      "148513                         0.00                         0.00   \n",
      "148514                         0.00                         0.00   \n",
      "148515                         0.00                         0.00   \n",
      "\n",
      "        dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
      "0                       0.00                      0.00                  0.05   \n",
      "1                       0.00                      0.00                  0.00   \n",
      "2                       1.00                      1.00                  0.00   \n",
      "3                       0.03                      0.01                  0.00   \n",
      "4                       0.00                      0.00                  0.00   \n",
      "5                       0.00                      0.00                  1.00   \n",
      "6                       1.00                      1.00                  0.00   \n",
      "7                       1.00                      1.00                  0.00   \n",
      "8                       1.00                      1.00                  0.00   \n",
      "9                       1.00                      1.00                  0.00   \n",
      "10                      0.00                      0.00                  1.00   \n",
      "11                      1.00                      1.00                  0.00   \n",
      "12                      0.00                      0.00                  0.00   \n",
      "13                      0.00                      0.00                  0.00   \n",
      "14                      1.00                      1.00                  0.00   \n",
      "15                      1.00                      1.00                  0.00   \n",
      "16                      0.00                      0.00                  0.00   \n",
      "17                      0.00                      0.00                  0.00   \n",
      "18                      0.00                      0.00                  0.02   \n",
      "19                      0.00                      0.00                  0.00   \n",
      "20                      1.00                      1.00                  0.00   \n",
      "21                      0.99                      1.00                  0.00   \n",
      "22                      0.00                      0.00                  0.00   \n",
      "23                      0.00                      0.00                  0.00   \n",
      "24                      1.00                      1.00                  0.00   \n",
      "25                      0.53                      0.00                  0.02   \n",
      "26                      1.00                      1.00                  0.00   \n",
      "27                      0.00                      0.00                  0.56   \n",
      "28                      0.00                      0.00                  0.00   \n",
      "29                      0.00                      0.00                  0.00   \n",
      "...                      ...                       ...                   ...   \n",
      "148486                  0.00                      0.00                  0.07   \n",
      "148487                  0.56                      0.56                  0.41   \n",
      "148488                  0.00                      0.00                  0.00   \n",
      "148489                  0.36                      0.37                  0.01   \n",
      "148490                  0.00                      0.00                  0.00   \n",
      "148491                  0.00                      0.00                  0.84   \n",
      "148492                  0.04                      0.00                  0.85   \n",
      "148493                  0.00                      0.00                  0.03   \n",
      "148494                  0.01                      0.01                  0.05   \n",
      "148495                  0.00                      0.00                  0.00   \n",
      "148496                  0.00                      0.00                  0.00   \n",
      "148497                  0.02                      0.02                  0.55   \n",
      "148498                  0.00                      0.00                  0.00   \n",
      "148499                  0.00                      0.00                  0.00   \n",
      "148500                  0.00                      0.00                  0.00   \n",
      "148501                  0.00                      0.00                  0.01   \n",
      "148502                  0.79                      0.29                  0.21   \n",
      "148503                  1.00                      1.00                  0.00   \n",
      "148504                  0.00                      0.00                  0.00   \n",
      "148505                  0.00                      0.00                  0.00   \n",
      "148506                  0.00                      0.00                  1.00   \n",
      "148507                  0.00                      0.00                  0.00   \n",
      "148508                  0.00                      0.00                  1.00   \n",
      "148509                  0.00                      0.00                  0.26   \n",
      "148510                  0.00                      0.00                  0.00   \n",
      "148511                  0.01                      0.00                  0.00   \n",
      "148512                  0.01                      0.00                  0.00   \n",
      "148513                  0.00                      0.00                  0.07   \n",
      "148514                  0.00                      0.00                  0.00   \n",
      "148515                  0.00                      0.00                  0.44   \n",
      "\n",
      "        dst_host_srv_rerror_rate         class  \n",
      "0                           0.00        normal  \n",
      "1                           0.00        normal  \n",
      "2                           0.00       neptune  \n",
      "3                           0.01        normal  \n",
      "4                           0.00        normal  \n",
      "5                           1.00       neptune  \n",
      "6                           0.00       neptune  \n",
      "7                           0.00       neptune  \n",
      "8                           0.00       neptune  \n",
      "9                           0.00       neptune  \n",
      "10                          1.00       neptune  \n",
      "11                          0.00       neptune  \n",
      "12                          0.00        normal  \n",
      "13                          0.00   warezclient  \n",
      "14                          0.00       neptune  \n",
      "15                          0.00       neptune  \n",
      "16                          0.00        normal  \n",
      "17                          0.00       ipsweep  \n",
      "18                          0.00        normal  \n",
      "19                          0.00        normal  \n",
      "20                          0.00       neptune  \n",
      "21                          0.00       neptune  \n",
      "22                          0.00        normal  \n",
      "23                          0.00        normal  \n",
      "24                          0.00       neptune  \n",
      "25                          0.16        normal  \n",
      "26                          0.00       neptune  \n",
      "27                          0.57        normal  \n",
      "28                          0.00        normal  \n",
      "29                          0.00        normal  \n",
      "...                          ...           ...  \n",
      "148486                      0.00        normal  \n",
      "148487                      0.41       apache2  \n",
      "148488                      0.00        normal  \n",
      "148489                      0.01  processtable  \n",
      "148490                      0.00        normal  \n",
      "148491                      0.00  processtable  \n",
      "148492                      1.00         satan  \n",
      "148493                      0.00         satan  \n",
      "148494                      0.05          back  \n",
      "148495                      0.00        normal  \n",
      "148496                      0.00       rootkit  \n",
      "148497                      0.57       apache2  \n",
      "148498                      0.00        normal  \n",
      "148499                      0.00        normal  \n",
      "148500                      0.00         smurf  \n",
      "148501                      0.00        normal  \n",
      "148502                      0.71       neptune  \n",
      "148503                      0.00       neptune  \n",
      "148504                      0.00        normal  \n",
      "148505                      0.00        normal  \n",
      "148506                      1.00       neptune  \n",
      "148507                      0.00        normal  \n",
      "148508                      1.00       neptune  \n",
      "148509                      0.00      mailbomb  \n",
      "148510                      0.00         smurf  \n",
      "148511                      0.00        normal  \n",
      "148512                      0.00        normal  \n",
      "148513                      0.07          back  \n",
      "148514                      0.00        normal  \n",
      "148515                      1.00         mscan  \n",
      "\n",
      "[148516 rows x 42 columns]\n",
      "['normal' 'neptune' 'warezclient' 'ipsweep' 'portsweep' 'teardrop' 'nmap'\n",
      " 'satan' 'smurf' 'pod' 'back' 'guess_passwd' 'ftp_write' 'multihop'\n",
      " 'rootkit' 'buffer_overflow' 'imap' 'warezmaster' 'phf' 'land'\n",
      " 'loadmodule' 'spy' 'perl' 'saint' 'mscan' 'apache2' 'snmpgetattack'\n",
      " 'processtable' 'httptunnel' 'ps' 'snmpguess' 'mailbomb' 'named'\n",
      " 'sendmail' 'xterm' 'worm' 'xlock' 'xsnoop' 'sqlattack' 'udpstorm']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "normal    77053\n",
       "attack    71463\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata=pd.concat([traindata, testdata], axis=0, join='outer',ignore_index=True)\n",
    "print(alldata)\n",
    "#print(alldata['protocol_type'])\n",
    "class_names=alldata['class'].unique()\n",
    "print(class_names)\n",
    "\n",
    "mask = alldata['class'] != 'normal' \n",
    "alldata.loc[mask, 'class'] = 'attack'\n",
    "alldata['class'].value_counts()\n",
    "\n",
    "#alldata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   duration  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
      "0         0        491          0     0               0       0    0   \n",
      "1         0        146          0     0               0       0    0   \n",
      "2         0          0          0     0               0       0    0   \n",
      "3         0        232       8153     0               0       0    0   \n",
      "4         0        199        420     0               0       0    0   \n",
      "\n",
      "   num_failed_logins  logged_in  num_compromised  ...  REJ  RSTO  RSTOS0  \\\n",
      "0                  0          0                0  ...    0     0       0   \n",
      "1                  0          0                0  ...    0     0       0   \n",
      "2                  0          0                0  ...    0     0       0   \n",
      "3                  0          1                0  ...    0     0       0   \n",
      "4                  0          1                0  ...    0     0       0   \n",
      "\n",
      "   RSTR  S0  S1  S2  S3  SF  SH  \n",
      "0     0   0   0   0   0   1   0  \n",
      "1     0   0   0   0   0   1   0  \n",
      "2     0   1   0   0   0   0   0  \n",
      "3     0   0   0   0   0   1   0  \n",
      "4     0   0   0   0   0   1   0  \n",
      "\n",
      "[5 rows x 123 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "/home/dsu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#traindata.info()\n",
    "#traindata.describe()\n",
    "protocol_type_dummy=pd.get_dummies(alldata['protocol_type'])\n",
    "alldata=pd.concat([alldata,protocol_type_dummy],axis=1)\n",
    "del alldata['protocol_type']\n",
    "\n",
    "\n",
    "service_dummy=pd.get_dummies(alldata[\"service\"])\n",
    "alldata=pd.concat([alldata,service_dummy],axis=1)\n",
    "del alldata[\"service\"]\n",
    "\n",
    "flag_dummy=pd.get_dummies(alldata[\"flag\"])\n",
    "alldata=pd.concat([alldata,flag_dummy],axis=1)\n",
    "del alldata[\"flag\"]\n",
    "print(alldata.head())\n",
    "\n",
    "#print(protocol_type_dummy)\n",
    "\n",
    "encode_text_index(alldata, 'class')\n",
    "# Break into X (predictors) & y (prediction)\n",
    "x, y = to_xy(alldata,'class')\n",
    "\n",
    "traindata=alldata.ix[0:trainlen-1,:]\n",
    "testdata=alldata.ix[trainlen:alldata.shape[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Columns: 122 entries, duration to SH\n",
      "dtypes: float64(15), int64(23), uint8(84)\n",
      "memory usage: 46.6 MB\n",
      "Y info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Data columns (total 1 columns):\n",
      "class    125973 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 984.2 KB\n",
      "T info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22543 entries, 125973 to 148515\n",
      "Columns: 122 entries, duration to SH\n",
      "dtypes: float64(15), int64(23), uint8(84)\n",
      "memory usage: 8.3 MB\n",
      "C info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22543 entries, 125973 to 148515\n",
      "Data columns (total 1 columns):\n",
      "class    22543 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 176.2 KB\n",
      "(125973, 1, 122)\n",
      "(22543, 1, 122)\n",
      "Index(['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment',\n",
      "       'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised',\n",
      "       ...\n",
      "       'REJ', 'RSTO', 'RSTOS0', 'RSTR', 'S0', 'S1', 'S2', 'S3', 'SF', 'SH'],\n",
      "      dtype='object', length=122)\n",
      "Index(['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment',\n",
      "       'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised',\n",
      "       ...\n",
      "       'REJ', 'RSTO', 'RSTOS0', 'RSTR', 'S0', 'S1', 'S2', 'S3', 'SF', 'SH'],\n",
      "      dtype='object', length=122)\n"
     ]
    }
   ],
   "source": [
    "#X = traindata.iloc[:,1:42]\n",
    "#Y = traindata.iloc[:,0]\n",
    "#C = testdata.iloc[:,0]\n",
    "#T = testdata.iloc[:,1:42]\n",
    "\n",
    "X = traindata.drop('class', axis=1)\n",
    "Y = traindata[['class']]\n",
    "T = testdata.drop('class',axis=1)\n",
    "C = testdata[['class']]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "# summarize transformed data\n",
    "np.set_printoptions(precision=3)\n",
    "#print(trainX[0:5,:])\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "# summarize transformed data\n",
    "np.set_printoptions(precision=3)\n",
    "#print(testT[0:5,:])\n",
    "\n",
    "print(\"X info\")\n",
    "X.info()\n",
    "print(\"Y info\")\n",
    "Y.info()\n",
    "print(\"T info\")\n",
    "T.info()\n",
    "print(\"C info\")\n",
    "C.info()\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X.columns)\n",
    "print(T.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# all 122 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1001 15:05:35.893579 140236905699136 deprecation_wrapper.py:119] From /home/dsu/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1001 15:05:35.896083 140236905699136 deprecation_wrapper.py:119] From /home/dsu/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:504: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1001 15:05:35.899833 140236905699136 deprecation_wrapper.py:119] From /home/dsu/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3828: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1001 15:05:36.072204 140236905699136 deprecation_wrapper.py:119] From /home/dsu/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:126: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1001 15:05:36.078324 140236905699136 deprecation.py:506] From /home/dsu/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3135: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME BEGIN: 2019-10-01 15:05:35.893243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1001 15:05:36.154644 140236905699136 deprecation_wrapper.py:119] From /home/dsu/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:744: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1001 15:05:36.170573 140236905699136 deprecation_wrapper.py:119] From /home/dsu/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3066: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1001 15:05:36.193103 140236905699136 deprecation.py:323] From /home/dsu/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 125973 samples, validate on 22543 samples\n",
      "Epoch 1/45\n",
      "125973/125973 [==============================] - 53s 418us/step - loss: 0.1925 - acc: 0.9199 - val_loss: 1.0058 - val_acc: 0.7497\n",
      "Epoch 2/45\n",
      "125973/125973 [==============================] - 49s 392us/step - loss: 0.1411 - acc: 0.9491 - val_loss: 1.1199 - val_acc: 0.7407\n",
      "Epoch 3/45\n",
      "125973/125973 [==============================] - 50s 393us/step - loss: 0.1228 - acc: 0.9582 - val_loss: 1.1274 - val_acc: 0.7467\n",
      "Epoch 4/45\n",
      "125973/125973 [==============================] - 49s 390us/step - loss: 0.1156 - acc: 0.9607 - val_loss: 1.1018 - val_acc: 0.7661\n",
      "Epoch 5/45\n",
      "125973/125973 [==============================] - 50s 397us/step - loss: 0.1094 - acc: 0.9621 - val_loss: 1.0644 - val_acc: 0.7690\n",
      "Epoch 6/45\n",
      "125973/125973 [==============================] - 49s 391us/step - loss: 0.1051 - acc: 0.9633 - val_loss: 1.1171 - val_acc: 0.7564\n",
      "Epoch 7/45\n",
      "125973/125973 [==============================] - 49s 388us/step - loss: 0.1019 - acc: 0.9641 - val_loss: 1.0361 - val_acc: 0.7666\n",
      "Epoch 8/45\n",
      "125973/125973 [==============================] - 49s 387us/step - loss: 0.1001 - acc: 0.9642 - val_loss: 0.9754 - val_acc: 0.7654\n",
      "Epoch 9/45\n",
      "125973/125973 [==============================] - 49s 391us/step - loss: 0.0978 - acc: 0.9644 - val_loss: 1.0138 - val_acc: 0.7660\n",
      "Epoch 10/45\n",
      "125973/125973 [==============================] - 49s 391us/step - loss: 0.0963 - acc: 0.9648 - val_loss: 0.9469 - val_acc: 0.7676\n",
      "Epoch 11/45\n",
      "125973/125973 [==============================] - 49s 393us/step - loss: 0.0949 - acc: 0.9653 - val_loss: 1.0219 - val_acc: 0.7668\n",
      "Epoch 12/45\n",
      "125973/125973 [==============================] - 48s 384us/step - loss: 0.0931 - acc: 0.9656 - val_loss: 1.0014 - val_acc: 0.7680\n",
      "Epoch 13/45\n",
      "125973/125973 [==============================] - 48s 383us/step - loss: 0.0916 - acc: 0.9664 - val_loss: 1.1595 - val_acc: 0.7386\n",
      "Epoch 14/45\n",
      "125973/125973 [==============================] - 49s 389us/step - loss: 0.0900 - acc: 0.9667 - val_loss: 0.9378 - val_acc: 0.7749\n",
      "Epoch 15/45\n",
      "125973/125973 [==============================] - 49s 386us/step - loss: 0.0891 - acc: 0.9668 - val_loss: 1.0914 - val_acc: 0.7631\n",
      "Epoch 16/45\n",
      "125973/125973 [==============================] - 48s 381us/step - loss: 0.0872 - acc: 0.9675 - val_loss: 1.1025 - val_acc: 0.7644\n",
      "Epoch 17/45\n",
      "125973/125973 [==============================] - 49s 390us/step - loss: 0.0854 - acc: 0.9681 - val_loss: 1.0332 - val_acc: 0.7747\n",
      "Epoch 18/45\n",
      "125973/125973 [==============================] - 49s 387us/step - loss: 0.0841 - acc: 0.9684 - val_loss: 1.1169 - val_acc: 0.7613\n",
      "Epoch 19/45\n",
      "125973/125973 [==============================] - 49s 387us/step - loss: 0.0830 - acc: 0.9693 - val_loss: 1.0644 - val_acc: 0.7877\n",
      "Epoch 20/45\n",
      "125973/125973 [==============================] - 49s 390us/step - loss: 0.0825 - acc: 0.9693 - val_loss: 1.0950 - val_acc: 0.7821\n",
      "Epoch 21/45\n",
      "125973/125973 [==============================] - 48s 384us/step - loss: 0.0820 - acc: 0.9702 - val_loss: 0.9739 - val_acc: 0.7873\n",
      "Epoch 22/45\n",
      "125973/125973 [==============================] - 49s 387us/step - loss: 0.0816 - acc: 0.9698 - val_loss: 1.1806 - val_acc: 0.7442\n",
      "Epoch 23/45\n",
      "125973/125973 [==============================] - 49s 390us/step - loss: 0.0795 - acc: 0.9707 - val_loss: 1.0874 - val_acc: 0.7879\n",
      "Epoch 24/45\n",
      "125973/125973 [==============================] - 49s 386us/step - loss: 0.0787 - acc: 0.9710 - val_loss: 1.0305 - val_acc: 0.7883\n",
      "Epoch 25/45\n",
      "125973/125973 [==============================] - 49s 388us/step - loss: 0.0788 - acc: 0.9709 - val_loss: 1.2313 - val_acc: 0.7593\n",
      "Epoch 26/45\n",
      "125973/125973 [==============================] - 49s 389us/step - loss: 0.0786 - acc: 0.9712 - val_loss: 1.0827 - val_acc: 0.7685\n",
      "Epoch 27/45\n",
      "125973/125973 [==============================] - 48s 384us/step - loss: 0.0780 - acc: 0.9714 - val_loss: 1.1005 - val_acc: 0.7730\n",
      "Epoch 28/45\n",
      "125973/125973 [==============================] - 49s 387us/step - loss: 0.0775 - acc: 0.9714 - val_loss: 1.1152 - val_acc: 0.7850\n",
      "Epoch 29/45\n",
      "125973/125973 [==============================] - 49s 386us/step - loss: 0.0771 - acc: 0.9718 - val_loss: 1.2350 - val_acc: 0.7425\n",
      "Epoch 30/45\n",
      "125973/125973 [==============================] - 49s 388us/step - loss: 0.0766 - acc: 0.9723 - val_loss: 1.1724 - val_acc: 0.7682\n",
      "Epoch 31/45\n",
      "125973/125973 [==============================] - 48s 385us/step - loss: 0.0758 - acc: 0.9724 - val_loss: 1.2812 - val_acc: 0.7465\n",
      "Epoch 32/45\n",
      "125973/125973 [==============================] - 49s 388us/step - loss: 0.0754 - acc: 0.9726 - val_loss: 1.2729 - val_acc: 0.7629\n",
      "Epoch 33/45\n",
      "125973/125973 [==============================] - 49s 386us/step - loss: 0.0750 - acc: 0.9730 - val_loss: 1.1466 - val_acc: 0.7861\n",
      "Epoch 34/45\n",
      "125973/125973 [==============================] - 48s 384us/step - loss: 0.0745 - acc: 0.9731 - val_loss: 1.1167 - val_acc: 0.7831\n",
      "Epoch 35/45\n",
      "125973/125973 [==============================] - 49s 391us/step - loss: 0.0740 - acc: 0.9737 - val_loss: 1.1903 - val_acc: 0.7663\n",
      "Epoch 36/45\n",
      "125973/125973 [==============================] - 49s 386us/step - loss: 0.0731 - acc: 0.9741 - val_loss: 1.0702 - val_acc: 0.7907\n",
      "Epoch 37/45\n",
      "125973/125973 [==============================] - 49s 387us/step - loss: 0.0727 - acc: 0.9739 - val_loss: 1.2198 - val_acc: 0.7703\n",
      "Epoch 38/45\n",
      "125973/125973 [==============================] - 49s 386us/step - loss: 0.0728 - acc: 0.9740 - val_loss: 1.2648 - val_acc: 0.7574\n",
      "Epoch 39/45\n",
      "125973/125973 [==============================] - 49s 385us/step - loss: 0.0720 - acc: 0.9743 - val_loss: 1.1793 - val_acc: 0.7849\n",
      "Epoch 40/45\n",
      "125973/125973 [==============================] - 48s 382us/step - loss: 0.0717 - acc: 0.9748 - val_loss: 1.2017 - val_acc: 0.7689\n",
      "Epoch 41/45\n",
      "125973/125973 [==============================] - 48s 380us/step - loss: 0.0713 - acc: 0.9745 - val_loss: 1.1222 - val_acc: 0.7880\n",
      "Epoch 42/45\n",
      "125973/125973 [==============================] - 49s 389us/step - loss: 0.0710 - acc: 0.9749 - val_loss: 1.2241 - val_acc: 0.7829\n",
      "Epoch 43/45\n",
      "125973/125973 [==============================] - 48s 385us/step - loss: 0.0710 - acc: 0.9750 - val_loss: 1.2684 - val_acc: 0.7757\n",
      "Epoch 44/45\n",
      "125973/125973 [==============================] - 49s 386us/step - loss: 0.0702 - acc: 0.9752 - val_loss: 1.1593 - val_acc: 0.7892\n",
      "Epoch 45/45\n",
      "125973/125973 [==============================] - 48s 383us/step - loss: 0.0700 - acc: 0.9752 - val_loss: 1.1512 - val_acc: 0.7871\n",
      "22543/22543 [==============================] - 3s 123us/step\n",
      "\n",
      "Loss: 1.15, Accuracy: 78.71%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.65      0.78     12833\n",
      "           1       0.68      0.97      0.80      9710\n",
      "\n",
      "    accuracy                           0.79     22543\n",
      "   macro avg       0.82      0.81      0.79     22543\n",
      "weighted avg       0.84      0.79      0.79     22543\n",
      "\n",
      "TIME END: 2019-10-01 15:42:20.888818\n"
     ]
    }
   ],
   "source": [
    "print(\"TIME BEGIN:\",datetime.datetime.now())\n",
    "batch_size = 32\n",
    "n_neurons=80\n",
    "\n",
    "# 1. define the network\n",
    "model = Sequential()\n",
    "#model.add(LSTM(4,input_dim=(1,122)))  # try using a GRU instead, for fun\n",
    "#model.add(LSTM(4,input_shape=(1,122)))\n",
    "model.add(LSTM(n_neurons, input_shape=(1,122)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "#print(model.get_config())\n",
    "\n",
    "\n",
    "#model = Sequential([\n",
    "#    LSTM(4,input_shape=(1,122)),\n",
    "#    Dense(len(class_names), activation='softmax')\n",
    "#])\n",
    "\n",
    "#model.compile(\n",
    "#    optimizer='adam',\n",
    "#    loss='sparse_categorical_crossentropy',\n",
    "#    metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "sgd = optimizers.SGD(lr=0.5)\n",
    "model.compile(loss='binary_crossentropy',optimizer=sgd,metrics=['accuracy'])\n",
    "csv_logger = CSVLogger('all122featuresetlog.csv',separator=',', append=False)\n",
    "#checkpointer = callbacks.ModelCheckpoint(filepath=\"kddresults/lstm1layer/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "#csv_logger = CSVLogger('training_set_iranalysis.csv',separator=',', append=False)\n",
    "#model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=1000, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=45, validation_data=(X_test, y_test))\n",
    "\n",
    "#model.save(\"kddresults/lstm1layer/fullmodel/lstm1layer_model.hdf5\")\n",
    "# Save the model\n",
    "model.save('all122featuresModel.h5')\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "#np.savetxt('kddresults/lstm1layer/lstm1predicted.txt', y_pred, fmt='%01d')\n",
    "print(\"TIME END:\",datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.796867724867725"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(y_test, y_pred, labels=np.unique(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8331\n",
      "4502\n",
      "297\n",
      "9413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[8331, 4502],\n",
       "       [ 297, 9413]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
    "print(tn)\n",
    "print(fp)\n",
    "print(fn)\n",
    "print(tp)\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.796867724867725"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "metrics.f1_score(y_test, y_pred, labels=np.unique(y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "/home/dsu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Data columns (total 3 columns):\n",
      "src_bytes    125973 non-null int64\n",
      "ecr_i        125973 non-null uint8\n",
      "http         125973 non-null uint8\n",
      "dtypes: int64(1), uint8(2)\n",
      "memory usage: 1.2 MB\n",
      "Y info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Data columns (total 1 columns):\n",
      "class    125973 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 984.2 KB\n",
      "T info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22543 entries, 125973 to 148515\n",
      "Data columns (total 3 columns):\n",
      "src_bytes    22543 non-null int64\n",
      "ecr_i        22543 non-null uint8\n",
      "http         22543 non-null uint8\n",
      "dtypes: int64(1), uint8(2)\n",
      "memory usage: 220.2 KB\n",
      "C info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22543 entries, 125973 to 148515\n",
      "Data columns (total 1 columns):\n",
      "class    22543 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 176.2 KB\n",
      "(125973, 1, 3)\n",
      "(22543, 1, 3)\n",
      "Index(['src_bytes', 'ecr_i', 'http'], dtype='object')\n",
      "Index(['src_bytes', 'ecr_i', 'http'], dtype='object')\n",
      "TIME BEGIN: 2019-10-01 16:28:44.940041\n",
      "Train on 125973 samples, validate on 22543 samples\n",
      "Epoch 1/45\n",
      "125973/125973 [==============================] - 50s 397us/step - loss: 0.3232 - acc: 0.8824 - val_loss: 0.5377 - val_acc: 0.7411\n",
      "Epoch 2/45\n",
      "125973/125973 [==============================] - 48s 383us/step - loss: 0.3140 - acc: 0.8858 - val_loss: 0.5318 - val_acc: 0.7411\n",
      "Epoch 3/45\n",
      "125973/125973 [==============================] - 48s 383us/step - loss: 0.3136 - acc: 0.8858 - val_loss: 0.5388 - val_acc: 0.7411\n",
      "Epoch 4/45\n",
      "125973/125973 [==============================] - 48s 377us/step - loss: 0.3133 - acc: 0.8858 - val_loss: 0.5388 - val_acc: 0.7411\n",
      "Epoch 5/45\n",
      "125973/125973 [==============================] - 48s 384us/step - loss: 0.3130 - acc: 0.8858 - val_loss: 0.5933 - val_acc: 0.7411\n",
      "Epoch 6/45\n",
      "125973/125973 [==============================] - 47s 375us/step - loss: 0.3131 - acc: 0.8858 - val_loss: 0.5446 - val_acc: 0.7411\n",
      "Epoch 7/45\n",
      "125973/125973 [==============================] - 47s 373us/step - loss: 0.3128 - acc: 0.8858 - val_loss: 0.5488 - val_acc: 0.7411\n",
      "Epoch 8/45\n",
      "125973/125973 [==============================] - 47s 373us/step - loss: 0.3126 - acc: 0.8858 - val_loss: 0.5388 - val_acc: 0.7411\n",
      "Epoch 9/45\n",
      "125973/125973 [==============================] - 47s 373us/step - loss: 0.3125 - acc: 0.8858 - val_loss: 0.5940 - val_acc: 0.7411\n",
      "Epoch 10/45\n",
      "125973/125973 [==============================] - 47s 374us/step - loss: 0.3124 - acc: 0.8858 - val_loss: 0.5700 - val_acc: 0.7411\n",
      "Epoch 11/45\n",
      "125973/125973 [==============================] - 47s 373us/step - loss: 0.3125 - acc: 0.8858 - val_loss: 0.5298 - val_acc: 0.7411\n",
      "Epoch 12/45\n",
      "125973/125973 [==============================] - 47s 377us/step - loss: 0.3126 - acc: 0.8858 - val_loss: 0.5510 - val_acc: 0.7411\n",
      "Epoch 13/45\n",
      "125973/125973 [==============================] - 47s 374us/step - loss: 0.3123 - acc: 0.8858 - val_loss: 0.5728 - val_acc: 0.7411\n",
      "Epoch 14/45\n",
      "125973/125973 [==============================] - 48s 378us/step - loss: 0.3124 - acc: 0.8858 - val_loss: 0.5812 - val_acc: 0.7411\n",
      "Epoch 15/45\n",
      "125973/125973 [==============================] - 48s 377us/step - loss: 0.3125 - acc: 0.8858 - val_loss: 0.5747 - val_acc: 0.7411\n",
      "Epoch 16/45\n",
      "125973/125973 [==============================] - 47s 375us/step - loss: 0.3122 - acc: 0.8858 - val_loss: 0.5281 - val_acc: 0.7411\n",
      "Epoch 17/45\n",
      "125973/125973 [==============================] - 47s 374us/step - loss: 0.3122 - acc: 0.8858 - val_loss: 0.5559 - val_acc: 0.7411\n",
      "Epoch 18/45\n",
      "125973/125973 [==============================] - 47s 375us/step - loss: 0.3122 - acc: 0.8858 - val_loss: 0.5580 - val_acc: 0.7411\n",
      "Epoch 19/45\n",
      "125973/125973 [==============================] - 48s 378us/step - loss: 0.3123 - acc: 0.8858 - val_loss: 0.5467 - val_acc: 0.7411\n",
      "Epoch 20/45\n",
      "125973/125973 [==============================] - 47s 376us/step - loss: 0.3122 - acc: 0.8858 - val_loss: 0.5799 - val_acc: 0.7411\n",
      "Epoch 21/45\n",
      "125973/125973 [==============================] - 48s 379us/step - loss: 0.3122 - acc: 0.8858 - val_loss: 0.5608 - val_acc: 0.7411\n",
      "Epoch 22/45\n",
      "125973/125973 [==============================] - 47s 371us/step - loss: 0.3121 - acc: 0.8858 - val_loss: 0.5621 - val_acc: 0.7411\n",
      "Epoch 23/45\n",
      "125973/125973 [==============================] - 47s 373us/step - loss: 0.3121 - acc: 0.8858 - val_loss: 0.5384 - val_acc: 0.7411\n",
      "Epoch 24/45\n",
      "125973/125973 [==============================] - 47s 375us/step - loss: 0.3121 - acc: 0.8858 - val_loss: 0.5916 - val_acc: 0.7411\n",
      "Epoch 25/45\n",
      "125973/125973 [==============================] - 47s 374us/step - loss: 0.3121 - acc: 0.8858 - val_loss: 0.5410 - val_acc: 0.7411\n",
      "Epoch 26/45\n",
      "125973/125973 [==============================] - 47s 376us/step - loss: 0.3119 - acc: 0.8858 - val_loss: 0.5556 - val_acc: 0.7411\n",
      "Epoch 27/45\n",
      "125973/125973 [==============================] - 47s 374us/step - loss: 0.3119 - acc: 0.8858 - val_loss: 0.5498 - val_acc: 0.7411\n",
      "Epoch 28/45\n",
      "125973/125973 [==============================] - 47s 373us/step - loss: 0.3121 - acc: 0.8858 - val_loss: 0.5607 - val_acc: 0.7411\n",
      "Epoch 29/45\n",
      "125973/125973 [==============================] - 48s 378us/step - loss: 0.3119 - acc: 0.8858 - val_loss: 0.5364 - val_acc: 0.7411\n",
      "Epoch 30/45\n",
      "125973/125973 [==============================] - 47s 375us/step - loss: 0.3121 - acc: 0.8858 - val_loss: 0.5382 - val_acc: 0.7411\n",
      "Epoch 31/45\n",
      "125973/125973 [==============================] - 47s 375us/step - loss: 0.3121 - acc: 0.8858 - val_loss: 0.5533 - val_acc: 0.7411\n",
      "Epoch 32/45\n",
      "125973/125973 [==============================] - 48s 378us/step - loss: 0.3118 - acc: 0.8858 - val_loss: 0.6126 - val_acc: 0.7411\n",
      "Epoch 33/45\n",
      "125973/125973 [==============================] - 47s 376us/step - loss: 0.3118 - acc: 0.8858 - val_loss: 0.5530 - val_acc: 0.7411\n",
      "Epoch 34/45\n",
      "125973/125973 [==============================] - 47s 377us/step - loss: 0.3119 - acc: 0.8858 - val_loss: 0.5383 - val_acc: 0.7411\n",
      "Epoch 35/45\n",
      "125973/125973 [==============================] - 47s 375us/step - loss: 0.3118 - acc: 0.8858 - val_loss: 0.5554 - val_acc: 0.7411\n",
      "Epoch 36/45\n",
      "125973/125973 [==============================] - 48s 378us/step - loss: 0.3118 - acc: 0.8858 - val_loss: 0.5704 - val_acc: 0.7411\n",
      "Epoch 37/45\n",
      "125973/125973 [==============================] - 48s 377us/step - loss: 0.3119 - acc: 0.8858 - val_loss: 0.5272 - val_acc: 0.7411\n",
      "Epoch 38/45\n",
      "125973/125973 [==============================] - 47s 376us/step - loss: 0.3118 - acc: 0.8858 - val_loss: 0.5079 - val_acc: 0.7411\n",
      "Epoch 39/45\n",
      "125973/125973 [==============================] - 48s 378us/step - loss: 0.3117 - acc: 0.8858 - val_loss: 0.5373 - val_acc: 0.7411\n",
      "Epoch 40/45\n",
      "125973/125973 [==============================] - 47s 376us/step - loss: 0.3119 - acc: 0.8858 - val_loss: 0.5968 - val_acc: 0.7411\n",
      "Epoch 41/45\n",
      "125973/125973 [==============================] - 47s 374us/step - loss: 0.3118 - acc: 0.8858 - val_loss: 0.5592 - val_acc: 0.7411\n",
      "Epoch 42/45\n",
      "125973/125973 [==============================] - 47s 375us/step - loss: 0.3118 - acc: 0.8858 - val_loss: 0.5415 - val_acc: 0.7411\n",
      "Epoch 43/45\n",
      "125973/125973 [==============================] - 48s 379us/step - loss: 0.3117 - acc: 0.8858 - val_loss: 0.5351 - val_acc: 0.7411\n",
      "Epoch 44/45\n",
      "125973/125973 [==============================] - 48s 377us/step - loss: 0.3116 - acc: 0.8858 - val_loss: 0.5829 - val_acc: 0.7411\n",
      "Epoch 45/45\n",
      "125973/125973 [==============================] - 48s 378us/step - loss: 0.3116 - acc: 0.8858 - val_loss: 0.5360 - val_acc: 0.7411\n",
      "22543/22543 [==============================] - 3s 118us/step\n",
      "\n",
      "Loss: 0.54, Accuracy: 74.11%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.56      0.71     12833\n",
      "           1       0.63      0.99      0.77      9710\n",
      "\n",
      "    accuracy                           0.74     22543\n",
      "   macro avg       0.80      0.77      0.74     22543\n",
      "weighted avg       0.83      0.74      0.73     22543\n",
      "\n",
      "TIME END: 2019-10-01 17:04:25.696636\n",
      "7135\n",
      "5698\n",
      "138\n",
      "9572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7135, 5698],\n",
       "       [ 138, 9572]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata.head()\n",
    "#col_list=['dst_host_diff_srv_rate','dst_host_serror_rate','serror_rate','dst_host_same_src_port_rate','S0','dst_host_srv_serror_rate','class']\n",
    "#col_list=['class','ecr_i','src_bytes','http','dst_bytes','count','private','dst_host_srv_count','dst_host_same_srv_rate','dst_host_same_src_port_rate','hot','dst_host_srv_serror_rate','is_guest_login','icmp','REJ','dst_host_serror_rate','dst_host_srv_diff_host_rate','tcp','urp_i','dst_host_rerror_rate','finger']\n",
    "#col_list=['class','ecr_i','src_bytes','http','dst_bytes','count','private','dst_host_srv_count','dst_host_same_srv_rate','dst_host_same_src_port_rate','hot']\n",
    "#col_list=['class','ecr_i','src_bytes','http','dst_bytes','count']\n",
    "\n",
    "\n",
    "#10 feature set\n",
    "#col_list=['class','src_bytes', 'dst_bytes','hot','count','dst_host_srv_count','dst_host_same_srv_rate','dst_host_same_src_port_rate','ecr_i','http','private']\n",
    "\n",
    "#8 feature set\n",
    "#col_list=['class','src_bytes', 'dst_bytes','hot','count','dst_host_same_srv_rate','ecr_i','http','private']\n",
    "\n",
    "#6 feature set\n",
    "#col_list=['class','src_bytes', 'dst_bytes','hot','count','ecr_i','http']\n",
    "\n",
    "#4 feature set\n",
    "#col_list=['class','src_bytes', 'dst_bytes','ecr_i','http']\n",
    "\n",
    "#3 feature set\n",
    "col_list=['class','src_bytes', 'ecr_i','http']\n",
    "\n",
    "#col_list=['class','ecr_i','http','src_bytes','hot','dst_bytes','dst_host_same_srv_rate']\n",
    "alldata2=alldata[col_list]\n",
    "traindata=alldata2.ix[0:trainlen-1,:]\n",
    "testdata=alldata2.ix[trainlen:alldata2.shape[0],:]\n",
    "\n",
    "\n",
    "#X = traindata.iloc[:,1:42]\n",
    "#Y = traindata.iloc[:,0]\n",
    "#C = testdata.iloc[:,0]\n",
    "#T = testdata.iloc[:,1:42]\n",
    "\n",
    "X = traindata.drop('class', axis=1)\n",
    "Y = traindata[['class']]\n",
    "T = testdata.drop('class',axis=1)\n",
    "C = testdata[['class']]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "# summarize transformed data\n",
    "np.set_printoptions(precision=3)\n",
    "#print(trainX[0:5,:])\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "# summarize transformed data\n",
    "np.set_printoptions(precision=3)\n",
    "#print(testT[0:5,:])\n",
    "\n",
    "print(\"X info\")\n",
    "X.info()\n",
    "print(\"Y info\")\n",
    "Y.info()\n",
    "print(\"T info\")\n",
    "T.info()\n",
    "print(\"C info\")\n",
    "C.info()\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X.columns)\n",
    "print(T.columns)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "#model = Sequential()\n",
    "#model.add(LSTM(4,input_dim=(1,122)))  # try using a GRU instead, for fun\n",
    "\n",
    "\n",
    "\n",
    "# configure network\n",
    "print(\"TIME BEGIN:\",datetime.datetime.now())\n",
    "n_epoch = 100\n",
    "n_neurons = 80\n",
    "# design network\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(LSTM(n_neurons,input_shape=(1,3)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "#print(model.get_config())\n",
    "\n",
    "\n",
    "#model = Sequential([\n",
    "#    LSTM(4,input_shape=(1,122)),\n",
    "#    Dense(len(class_names), activation='softmax')\n",
    "#])\n",
    "\n",
    "#model.compile(\n",
    "#    optimizer='adam',\n",
    "#    loss='sparse_categorical_crossentropy',\n",
    "#    metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "sgd = optimizers.SGD(lr=0.5)\n",
    "model.compile(loss='binary_crossentropy',optimizer=sgd,metrics=['accuracy'])\n",
    "#model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "#checkpointer = callbacks.ModelCheckpoint(filepath=\"kddresults/lstm1layer/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('3featuresetlog.csv',separator=',', append=False)\n",
    "#model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=1000, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=45, validation_data=(X_test, y_test),callbacks=[csv_logger])\n",
    "\n",
    "#model.save(\"kddresults/lstm1layer/fullmodel/lstm1layer_model.hdf5\")\n",
    "# Save the model\n",
    "model.save('3featureModel.h5')\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "#np.savetxt('kddresults/lstm1layer/lstm1predicted.txt', y_pred, fmt='%01d')\n",
    "\n",
    "print(\"TIME END:\",datetime.datetime.now())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
    "print(tn)\n",
    "print(fp)\n",
    "print(fn)\n",
    "print(tp)\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7663730984787831"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(y_test, y_pred, labels=np.unique(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "/home/dsu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1001 13:44:23.675068 140611690805056 deprecation_wrapper.py:119] From /home/dsu/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1001 13:44:23.677129 140611690805056 deprecation_wrapper.py:119] From /home/dsu/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:504: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1001 13:44:23.681242 140611690805056 deprecation_wrapper.py:119] From /home/dsu/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3828: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1001 13:44:23.830312 140611690805056 deprecation_wrapper.py:119] From /home/dsu/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:126: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1001 13:44:23.835547 140611690805056 deprecation.py:506] From /home/dsu/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3135: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Data columns (total 4 columns):\n",
      "src_bytes    125973 non-null int64\n",
      "dst_bytes    125973 non-null int64\n",
      "ecr_i        125973 non-null uint8\n",
      "http         125973 non-null uint8\n",
      "dtypes: int64(2), uint8(2)\n",
      "memory usage: 2.2 MB\n",
      "Y info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Data columns (total 1 columns):\n",
      "class    125973 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 984.2 KB\n",
      "T info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22543 entries, 125973 to 148515\n",
      "Data columns (total 4 columns):\n",
      "src_bytes    22543 non-null int64\n",
      "dst_bytes    22543 non-null int64\n",
      "ecr_i        22543 non-null uint8\n",
      "http         22543 non-null uint8\n",
      "dtypes: int64(2), uint8(2)\n",
      "memory usage: 396.3 KB\n",
      "C info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22543 entries, 125973 to 148515\n",
      "Data columns (total 1 columns):\n",
      "class    22543 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 176.2 KB\n",
      "(125973, 1, 4)\n",
      "(22543, 1, 4)\n",
      "Index(['src_bytes', 'dst_bytes', 'ecr_i', 'http'], dtype='object')\n",
      "Index(['src_bytes', 'dst_bytes', 'ecr_i', 'http'], dtype='object')\n",
      "TIME BEGIN: 2019-10-01 13:44:23.674661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1001 13:44:23.865136 140611690805056 deprecation_wrapper.py:119] From /home/dsu/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:744: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1001 13:44:23.869014 140611690805056 deprecation_wrapper.py:119] From /home/dsu/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3066: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1001 13:44:23.872488 140611690805056 deprecation.py:323] From /home/dsu/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 125973 samples, validate on 22543 samples\n",
      "Epoch 1/45\n",
      "125973/125973 [==============================] - 38s 303us/step - loss: 0.2014 - acc: 0.9015 - val_loss: 0.8612 - val_acc: 0.7684\n",
      "Epoch 2/45\n",
      "125973/125973 [==============================] - 35s 280us/step - loss: 0.1890 - acc: 0.9065 - val_loss: 0.9061 - val_acc: 0.7691\n",
      "Epoch 3/45\n",
      "125973/125973 [==============================] - 35s 277us/step - loss: 0.1884 - acc: 0.9071 - val_loss: 0.9073 - val_acc: 0.6985\n",
      "Epoch 4/45\n",
      "125973/125973 [==============================] - 35s 280us/step - loss: 0.1881 - acc: 0.9068 - val_loss: 0.8373 - val_acc: 0.7683\n",
      "Epoch 5/45\n",
      "125973/125973 [==============================] - 35s 280us/step - loss: 0.1879 - acc: 0.9079 - val_loss: 0.8176 - val_acc: 0.7682\n",
      "Epoch 6/45\n",
      "125973/125973 [==============================] - 35s 278us/step - loss: 0.1879 - acc: 0.9078 - val_loss: 0.8674 - val_acc: 0.7686\n",
      "Epoch 7/45\n",
      "125973/125973 [==============================] - 33s 261us/step - loss: 0.1876 - acc: 0.9081 - val_loss: 0.8386 - val_acc: 0.7685\n",
      "Epoch 8/45\n",
      "125973/125973 [==============================] - 38s 302us/step - loss: 0.1874 - acc: 0.9081 - val_loss: 0.8643 - val_acc: 0.7685\n",
      "Epoch 9/45\n",
      "125973/125973 [==============================] - 44s 353us/step - loss: 0.1873 - acc: 0.9084 - val_loss: 0.8987 - val_acc: 0.7689\n",
      "Epoch 10/45\n",
      "125973/125973 [==============================] - 45s 360us/step - loss: 0.1871 - acc: 0.9085 - val_loss: 0.7933 - val_acc: 0.7681\n",
      "Epoch 11/45\n",
      "125973/125973 [==============================] - 47s 370us/step - loss: 0.1873 - acc: 0.9084 - val_loss: 0.8342 - val_acc: 0.7684\n",
      "Epoch 12/45\n",
      "125973/125973 [==============================] - 47s 373us/step - loss: 0.1873 - acc: 0.9084 - val_loss: 0.8559 - val_acc: 0.7690\n",
      "Epoch 13/45\n",
      "125973/125973 [==============================] - 47s 372us/step - loss: 0.1873 - acc: 0.9087 - val_loss: 0.8750 - val_acc: 0.7687\n",
      "Epoch 14/45\n",
      "125973/125973 [==============================] - 47s 375us/step - loss: 0.1872 - acc: 0.9090 - val_loss: 0.8414 - val_acc: 0.7686\n",
      "Epoch 15/45\n",
      "125973/125973 [==============================] - 47s 370us/step - loss: 0.1870 - acc: 0.9088 - val_loss: 0.8703 - val_acc: 0.7691\n",
      "Epoch 16/45\n",
      "125973/125973 [==============================] - 47s 371us/step - loss: 0.1870 - acc: 0.9089 - val_loss: 0.8836 - val_acc: 0.7687\n",
      "Epoch 17/45\n",
      "125973/125973 [==============================] - 47s 375us/step - loss: 0.1867 - acc: 0.9090 - val_loss: 0.8409 - val_acc: 0.7685\n",
      "Epoch 18/45\n",
      "125973/125973 [==============================] - 47s 374us/step - loss: 0.1867 - acc: 0.9088 - val_loss: 0.8383 - val_acc: 0.7683\n",
      "Epoch 19/45\n",
      "125973/125973 [==============================] - 47s 374us/step - loss: 0.1868 - acc: 0.9086 - val_loss: 0.8699 - val_acc: 0.7685\n",
      "Epoch 20/45\n",
      "125973/125973 [==============================] - 48s 380us/step - loss: 0.1868 - acc: 0.9088 - val_loss: 0.8441 - val_acc: 0.7685\n",
      "Epoch 21/45\n",
      "125973/125973 [==============================] - 47s 371us/step - loss: 0.1867 - acc: 0.9090 - val_loss: 0.8085 - val_acc: 0.7683\n",
      "Epoch 22/45\n",
      "125973/125973 [==============================] - 47s 376us/step - loss: 0.1866 - acc: 0.9089 - val_loss: 0.8664 - val_acc: 0.7691\n",
      "Epoch 23/45\n",
      "125973/125973 [==============================] - 47s 373us/step - loss: 0.1867 - acc: 0.9086 - val_loss: 0.8078 - val_acc: 0.7684\n",
      "Epoch 24/45\n",
      "125973/125973 [==============================] - 47s 373us/step - loss: 0.1866 - acc: 0.9091 - val_loss: 0.8525 - val_acc: 0.7684\n",
      "Epoch 25/45\n",
      "125973/125973 [==============================] - 47s 373us/step - loss: 0.1868 - acc: 0.9091 - val_loss: 0.8709 - val_acc: 0.7691\n",
      "Epoch 26/45\n",
      "125973/125973 [==============================] - 47s 371us/step - loss: 0.1869 - acc: 0.9088 - val_loss: 0.8804 - val_acc: 0.7689\n",
      "Epoch 27/45\n",
      "125973/125973 [==============================] - 47s 376us/step - loss: 0.1865 - acc: 0.9089 - val_loss: 0.8077 - val_acc: 0.7684\n",
      "Epoch 28/45\n",
      "125973/125973 [==============================] - 47s 375us/step - loss: 0.1866 - acc: 0.9084 - val_loss: 0.8660 - val_acc: 0.7687\n",
      "Epoch 29/45\n",
      "125973/125973 [==============================] - 47s 374us/step - loss: 0.1867 - acc: 0.9092 - val_loss: 0.8817 - val_acc: 0.7691\n",
      "Epoch 30/45\n",
      "125973/125973 [==============================] - 47s 377us/step - loss: 0.1868 - acc: 0.9090 - val_loss: 0.8567 - val_acc: 0.7685\n",
      "Epoch 31/45\n",
      "125973/125973 [==============================] - 47s 375us/step - loss: 0.1865 - acc: 0.9093 - val_loss: 0.8676 - val_acc: 0.7686\n",
      "Epoch 32/45\n",
      "125973/125973 [==============================] - 47s 374us/step - loss: 0.1866 - acc: 0.9091 - val_loss: 0.8559 - val_acc: 0.7686\n",
      "Epoch 33/45\n",
      "125973/125973 [==============================] - 47s 373us/step - loss: 0.1866 - acc: 0.9091 - val_loss: 0.8280 - val_acc: 0.7685\n",
      "Epoch 34/45\n",
      "125973/125973 [==============================] - 47s 374us/step - loss: 0.1865 - acc: 0.9090 - val_loss: 0.8516 - val_acc: 0.7684\n",
      "Epoch 35/45\n",
      "125973/125973 [==============================] - 47s 373us/step - loss: 0.1863 - acc: 0.9093 - val_loss: 0.8768 - val_acc: 0.7691\n",
      "Epoch 36/45\n",
      "125973/125973 [==============================] - 47s 373us/step - loss: 0.1865 - acc: 0.9094 - val_loss: 0.8091 - val_acc: 0.7684\n",
      "Epoch 37/45\n",
      "125973/125973 [==============================] - 47s 373us/step - loss: 0.1866 - acc: 0.9092 - val_loss: 0.8655 - val_acc: 0.7691\n",
      "Epoch 38/45\n",
      "125973/125973 [==============================] - 47s 374us/step - loss: 0.1864 - acc: 0.9089 - val_loss: 0.8464 - val_acc: 0.7686\n",
      "Epoch 39/45\n",
      "125973/125973 [==============================] - 47s 375us/step - loss: 0.1865 - acc: 0.9091 - val_loss: 0.8685 - val_acc: 0.7690\n",
      "Epoch 40/45\n",
      "125973/125973 [==============================] - 47s 373us/step - loss: 0.1864 - acc: 0.9091 - val_loss: 0.8790 - val_acc: 0.7685\n",
      "Epoch 41/45\n",
      "125973/125973 [==============================] - 47s 374us/step - loss: 0.1864 - acc: 0.9094 - val_loss: 0.7890 - val_acc: 0.7683\n",
      "Epoch 42/45\n",
      "125973/125973 [==============================] - 47s 375us/step - loss: 0.1863 - acc: 0.9088 - val_loss: 0.8432 - val_acc: 0.7684\n",
      "Epoch 43/45\n",
      "125973/125973 [==============================] - 47s 373us/step - loss: 0.1864 - acc: 0.9090 - val_loss: 0.8773 - val_acc: 0.7691\n",
      "Epoch 44/45\n",
      "125973/125973 [==============================] - 47s 374us/step - loss: 0.1863 - acc: 0.9090 - val_loss: 0.8554 - val_acc: 0.7685\n",
      "Epoch 45/45\n",
      "125973/125973 [==============================] - 47s 377us/step - loss: 0.1864 - acc: 0.9092 - val_loss: 0.8112 - val_acc: 0.7684\n",
      "22543/22543 [==============================] - 3s 119us/step\n",
      "\n",
      "Loss: 0.81, Accuracy: 76.84%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.65      0.76     12833\n",
      "           1       0.67      0.92      0.77      9710\n",
      "\n",
      "    accuracy                           0.77     22543\n",
      "   macro avg       0.79      0.79      0.77     22543\n",
      "weighted avg       0.81      0.77      0.77     22543\n",
      "\n",
      "TIME END: 2019-10-01 14:18:12.355753\n",
      "8354\n",
      "4479\n",
      "741\n",
      "8969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[8354, 4479],\n",
       "       [ 741, 8969]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata.head()\n",
    "#col_list=['dst_host_diff_srv_rate','dst_host_serror_rate','serror_rate','dst_host_same_src_port_rate','S0','dst_host_srv_serror_rate','class']\n",
    "#col_list=['class','ecr_i','src_bytes','http','dst_bytes','count','private','dst_host_srv_count','dst_host_same_srv_rate','dst_host_same_src_port_rate','hot','dst_host_srv_serror_rate','is_guest_login','icmp','REJ','dst_host_serror_rate','dst_host_srv_diff_host_rate','tcp','urp_i','dst_host_rerror_rate','finger']\n",
    "#col_list=['class','ecr_i','src_bytes','http','dst_bytes','count','private','dst_host_srv_count','dst_host_same_srv_rate','dst_host_same_src_port_rate','hot']\n",
    "#col_list=['class','ecr_i','src_bytes','http','dst_bytes','count']\n",
    "\n",
    "\n",
    "#10 feature set\n",
    "#col_list=['class','src_bytes', 'dst_bytes','hot','count','dst_host_srv_count','dst_host_same_srv_rate','dst_host_same_src_port_rate','ecr_i','http','private']\n",
    "\n",
    "#8 feature set\n",
    "#col_list=['class','src_bytes', 'dst_bytes','hot','count','dst_host_same_srv_rate','ecr_i','http','private']\n",
    "\n",
    "#6 feature set\n",
    "#col_list=['class','src_bytes', 'dst_bytes','hot','count','ecr_i','http']\n",
    "\n",
    "#4 feature set\n",
    "col_list=['class','src_bytes', 'dst_bytes','ecr_i','http']\n",
    "\n",
    "#3 feature set\n",
    "#col_list=['class','src_bytes', 'ecr_i','http']\n",
    "\n",
    "#col_list=['class','ecr_i','http','src_bytes','hot','dst_bytes','dst_host_same_srv_rate']\n",
    "alldata2=alldata[col_list]\n",
    "traindata=alldata2.ix[0:trainlen-1,:]\n",
    "testdata=alldata2.ix[trainlen:alldata2.shape[0],:]\n",
    "\n",
    "\n",
    "#X = traindata.iloc[:,1:42]\n",
    "#Y = traindata.iloc[:,0]\n",
    "#C = testdata.iloc[:,0]\n",
    "#T = testdata.iloc[:,1:42]\n",
    "\n",
    "X = traindata.drop('class', axis=1)\n",
    "Y = traindata[['class']]\n",
    "T = testdata.drop('class',axis=1)\n",
    "C = testdata[['class']]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "# summarize transformed data\n",
    "np.set_printoptions(precision=3)\n",
    "#print(trainX[0:5,:])\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "# summarize transformed data\n",
    "np.set_printoptions(precision=3)\n",
    "#print(testT[0:5,:])\n",
    "\n",
    "print(\"X info\")\n",
    "X.info()\n",
    "print(\"Y info\")\n",
    "Y.info()\n",
    "print(\"T info\")\n",
    "T.info()\n",
    "print(\"C info\")\n",
    "C.info()\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X.columns)\n",
    "print(T.columns)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "#model = Sequential()\n",
    "#model.add(LSTM(4,input_dim=(1,122)))  # try using a GRU instead, for fun\n",
    "\n",
    "\n",
    "\n",
    "# configure network\n",
    "print(\"TIME BEGIN:\",datetime.datetime.now())\n",
    "n_epoch = 100\n",
    "n_neurons = 80\n",
    "# design network\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(LSTM(n_neurons,input_shape=(1,4)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "#print(model.get_config())\n",
    "\n",
    "\n",
    "#model = Sequential([\n",
    "#    LSTM(4,input_shape=(1,122)),\n",
    "#    Dense(len(class_names), activation='softmax')\n",
    "#])\n",
    "\n",
    "#model.compile(\n",
    "#    optimizer='adam',\n",
    "#    loss='sparse_categorical_crossentropy',\n",
    "#    metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "sgd = optimizers.SGD(lr=0.5)\n",
    "model.compile(loss='binary_crossentropy',optimizer=sgd,metrics=['accuracy'])\n",
    "#model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "#checkpointer = callbacks.ModelCheckpoint(filepath=\"kddresults/lstm1layer/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('4featuresetlog.csv',separator=',', append=False)\n",
    "#model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=1000, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=45, validation_data=(X_test, y_test),callbacks=[csv_logger])\n",
    "\n",
    "#model.save(\"kddresults/lstm1layer/fullmodel/lstm1layer_model.hdf5\")\n",
    "# Save the model\n",
    "model.save('4featureModel.h5')\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "#np.savetxt('kddresults/lstm1layer/lstm1predicted.txt', y_pred, fmt='%01d')\n",
    "\n",
    "print(\"TIME END:\",datetime.datetime.now())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
    "print(tn)\n",
    "print(fp)\n",
    "print(fn)\n",
    "print(tp)\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7745919336730287"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(y_test, y_pred, labels=np.unique(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "/home/dsu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1001 14:23:16.453169 140510210565952 deprecation_wrapper.py:119] From /home/dsu/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1001 14:23:16.455965 140510210565952 deprecation_wrapper.py:119] From /home/dsu/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:504: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1001 14:23:16.459254 140510210565952 deprecation_wrapper.py:119] From /home/dsu/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3828: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1001 14:23:16.603962 140510210565952 deprecation_wrapper.py:119] From /home/dsu/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:126: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Data columns (total 6 columns):\n",
      "src_bytes    125973 non-null int64\n",
      "dst_bytes    125973 non-null int64\n",
      "hot          125973 non-null int64\n",
      "count        125973 non-null int64\n",
      "ecr_i        125973 non-null uint8\n",
      "http         125973 non-null uint8\n",
      "dtypes: int64(4), uint8(2)\n",
      "memory usage: 4.1 MB\n",
      "Y info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Data columns (total 1 columns):\n",
      "class    125973 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 984.2 KB\n",
      "T info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22543 entries, 125973 to 148515\n",
      "Data columns (total 6 columns):\n",
      "src_bytes    22543 non-null int64\n",
      "dst_bytes    22543 non-null int64\n",
      "hot          22543 non-null int64\n",
      "count        22543 non-null int64\n",
      "ecr_i        22543 non-null uint8\n",
      "http         22543 non-null uint8\n",
      "dtypes: int64(4), uint8(2)\n",
      "memory usage: 748.6 KB\n",
      "C info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22543 entries, 125973 to 148515\n",
      "Data columns (total 1 columns):\n",
      "class    22543 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 176.2 KB\n",
      "(125973, 1, 6)\n",
      "(22543, 1, 6)\n",
      "Index(['src_bytes', 'dst_bytes', 'hot', 'count', 'ecr_i', 'http'], dtype='object')\n",
      "Index(['src_bytes', 'dst_bytes', 'hot', 'count', 'ecr_i', 'http'], dtype='object')\n",
      "TIME BEGIN: 2019-10-01 14:23:16.452651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1001 14:23:16.612241 140510210565952 deprecation.py:506] From /home/dsu/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3135: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1001 14:23:16.643925 140510210565952 deprecation_wrapper.py:119] From /home/dsu/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:744: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1001 14:23:16.649744 140510210565952 deprecation_wrapper.py:119] From /home/dsu/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3066: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1001 14:23:16.656026 140510210565952 deprecation.py:323] From /home/dsu/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 125973 samples, validate on 22543 samples\n",
      "Epoch 1/45\n",
      "125973/125973 [==============================] - 51s 408us/step - loss: 0.1756 - acc: 0.9300 - val_loss: 0.8794 - val_acc: 0.7462\n",
      "Epoch 2/45\n",
      "125973/125973 [==============================] - 49s 387us/step - loss: 0.1530 - acc: 0.9425 - val_loss: 0.9360 - val_acc: 0.7217\n",
      "Epoch 3/45\n",
      "125973/125973 [==============================] - 48s 385us/step - loss: 0.1512 - acc: 0.9453 - val_loss: 0.8779 - val_acc: 0.7233\n",
      "Epoch 4/45\n",
      "125973/125973 [==============================] - 48s 384us/step - loss: 0.1500 - acc: 0.9469 - val_loss: 0.8521 - val_acc: 0.7450\n",
      "Epoch 5/45\n",
      "125973/125973 [==============================] - 48s 379us/step - loss: 0.1491 - acc: 0.9477 - val_loss: 0.8024 - val_acc: 0.7464\n",
      "Epoch 6/45\n",
      "125973/125973 [==============================] - 48s 378us/step - loss: 0.1482 - acc: 0.9490 - val_loss: 0.8577 - val_acc: 0.7360\n",
      "Epoch 7/45\n",
      "125973/125973 [==============================] - 47s 377us/step - loss: 0.1475 - acc: 0.9495 - val_loss: 0.8205 - val_acc: 0.7397\n",
      "Epoch 8/45\n",
      "125973/125973 [==============================] - 47s 376us/step - loss: 0.1464 - acc: 0.9505 - val_loss: 0.8112 - val_acc: 0.7609\n",
      "Epoch 9/45\n",
      "125973/125973 [==============================] - 48s 378us/step - loss: 0.1457 - acc: 0.9510 - val_loss: 0.8792 - val_acc: 0.7424\n",
      "Epoch 10/45\n",
      "125973/125973 [==============================] - 48s 379us/step - loss: 0.1446 - acc: 0.9526 - val_loss: 0.7746 - val_acc: 0.7734\n",
      "Epoch 11/45\n",
      "125973/125973 [==============================] - 48s 382us/step - loss: 0.1437 - acc: 0.9538 - val_loss: 0.8369 - val_acc: 0.7594\n",
      "Epoch 12/45\n",
      "125973/125973 [==============================] - 47s 377us/step - loss: 0.1422 - acc: 0.9545 - val_loss: 0.8249 - val_acc: 0.7604\n",
      "Epoch 13/45\n",
      "125973/125973 [==============================] - 48s 377us/step - loss: 0.1413 - acc: 0.9552 - val_loss: 0.8511 - val_acc: 0.7627\n",
      "Epoch 14/45\n",
      "125973/125973 [==============================] - 48s 381us/step - loss: 0.1404 - acc: 0.9553 - val_loss: 0.8635 - val_acc: 0.7451\n",
      "Epoch 15/45\n",
      "125973/125973 [==============================] - 48s 381us/step - loss: 0.1393 - acc: 0.9553 - val_loss: 0.8636 - val_acc: 0.7461\n",
      "Epoch 16/45\n",
      "125973/125973 [==============================] - 48s 378us/step - loss: 0.1385 - acc: 0.9558 - val_loss: 0.8620 - val_acc: 0.7649\n",
      "Epoch 17/45\n",
      "125973/125973 [==============================] - 48s 379us/step - loss: 0.1378 - acc: 0.9559 - val_loss: 0.8571 - val_acc: 0.7487\n",
      "Epoch 18/45\n",
      "125973/125973 [==============================] - 48s 381us/step - loss: 0.1370 - acc: 0.9562 - val_loss: 0.8420 - val_acc: 0.7621\n",
      "Epoch 19/45\n",
      "125973/125973 [==============================] - 47s 375us/step - loss: 0.1368 - acc: 0.9555 - val_loss: 0.8387 - val_acc: 0.7708\n",
      "Epoch 20/45\n",
      "125973/125973 [==============================] - 48s 378us/step - loss: 0.1362 - acc: 0.9555 - val_loss: 0.8541 - val_acc: 0.7574\n",
      "Epoch 21/45\n",
      "125973/125973 [==============================] - 48s 378us/step - loss: 0.1361 - acc: 0.9556 - val_loss: 0.7771 - val_acc: 0.7745\n",
      "Epoch 22/45\n",
      "125973/125973 [==============================] - 47s 377us/step - loss: 0.1352 - acc: 0.9552 - val_loss: 0.8725 - val_acc: 0.7593\n",
      "Epoch 23/45\n",
      "125973/125973 [==============================] - 48s 382us/step - loss: 0.1352 - acc: 0.9553 - val_loss: 0.8168 - val_acc: 0.7560\n",
      "Epoch 24/45\n",
      "125973/125973 [==============================] - 48s 379us/step - loss: 0.1345 - acc: 0.9557 - val_loss: 0.8285 - val_acc: 0.7694\n",
      "Epoch 25/45\n",
      "125973/125973 [==============================] - 47s 375us/step - loss: 0.1340 - acc: 0.9555 - val_loss: 0.8323 - val_acc: 0.7630\n",
      "Epoch 26/45\n",
      "125973/125973 [==============================] - 48s 379us/step - loss: 0.1343 - acc: 0.9555 - val_loss: 0.8561 - val_acc: 0.7594\n",
      "Epoch 27/45\n",
      "125973/125973 [==============================] - 48s 379us/step - loss: 0.1333 - acc: 0.9554 - val_loss: 0.8040 - val_acc: 0.7657\n",
      "Epoch 28/45\n",
      "125973/125973 [==============================] - 48s 380us/step - loss: 0.1330 - acc: 0.9558 - val_loss: 0.8356 - val_acc: 0.7653\n",
      "Epoch 29/45\n",
      "125973/125973 [==============================] - 47s 376us/step - loss: 0.1327 - acc: 0.9557 - val_loss: 0.9010 - val_acc: 0.7600\n",
      "Epoch 30/45\n",
      "125973/125973 [==============================] - 48s 380us/step - loss: 0.1329 - acc: 0.9555 - val_loss: 0.8666 - val_acc: 0.7638\n",
      "Epoch 31/45\n",
      "125973/125973 [==============================] - 48s 382us/step - loss: 0.1320 - acc: 0.9558 - val_loss: 0.8553 - val_acc: 0.7624\n",
      "Epoch 32/45\n",
      "125973/125973 [==============================] - 47s 375us/step - loss: 0.1321 - acc: 0.9556 - val_loss: 0.8805 - val_acc: 0.7599\n",
      "Epoch 33/45\n",
      "125973/125973 [==============================] - 48s 378us/step - loss: 0.1317 - acc: 0.9556 - val_loss: 0.8173 - val_acc: 0.7642\n",
      "Epoch 34/45\n",
      "125973/125973 [==============================] - 48s 381us/step - loss: 0.1311 - acc: 0.9555 - val_loss: 0.8262 - val_acc: 0.7741\n",
      "Epoch 35/45\n",
      "125973/125973 [==============================] - 48s 380us/step - loss: 0.1309 - acc: 0.9556 - val_loss: 0.8049 - val_acc: 0.7640\n",
      "Epoch 36/45\n",
      "125973/125973 [==============================] - 48s 380us/step - loss: 0.1312 - acc: 0.9553 - val_loss: 0.7749 - val_acc: 0.7740\n",
      "Epoch 37/45\n",
      "125973/125973 [==============================] - 48s 378us/step - loss: 0.1305 - acc: 0.9551 - val_loss: 0.8855 - val_acc: 0.7500\n",
      "Epoch 38/45\n",
      "125973/125973 [==============================] - 48s 379us/step - loss: 0.1309 - acc: 0.9553 - val_loss: 0.8325 - val_acc: 0.7630\n",
      "Epoch 39/45\n",
      "125973/125973 [==============================] - 49s 386us/step - loss: 0.1302 - acc: 0.9556 - val_loss: 0.7901 - val_acc: 0.7690\n",
      "Epoch 40/45\n",
      "125973/125973 [==============================] - 48s 382us/step - loss: 0.1299 - acc: 0.9553 - val_loss: 0.8317 - val_acc: 0.7692\n",
      "Epoch 41/45\n",
      "125973/125973 [==============================] - 48s 382us/step - loss: 0.1299 - acc: 0.9554 - val_loss: 0.7501 - val_acc: 0.7643\n",
      "Epoch 42/45\n",
      "125973/125973 [==============================] - 48s 379us/step - loss: 0.1303 - acc: 0.9552 - val_loss: 0.8264 - val_acc: 0.7647\n",
      "Epoch 43/45\n",
      "125973/125973 [==============================] - 48s 380us/step - loss: 0.1301 - acc: 0.9552 - val_loss: 0.8797 - val_acc: 0.7603\n",
      "Epoch 44/45\n",
      "125973/125973 [==============================] - 48s 380us/step - loss: 0.1292 - acc: 0.9553 - val_loss: 0.8249 - val_acc: 0.7616\n",
      "Epoch 45/45\n",
      "125973/125973 [==============================] - 48s 381us/step - loss: 0.1295 - acc: 0.9549 - val_loss: 0.8098 - val_acc: 0.7560\n",
      "22543/22543 [==============================] - 3s 118us/step\n",
      "\n",
      "Loss: 0.81, Accuracy: 75.60%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.60      0.74     12833\n",
      "           1       0.65      0.96      0.77      9710\n",
      "\n",
      "    accuracy                           0.76     22543\n",
      "   macro avg       0.80      0.78      0.75     22543\n",
      "weighted avg       0.82      0.76      0.75     22543\n",
      "\n",
      "TIME END: 2019-10-01 14:59:17.265245\n",
      "7755\n",
      "5078\n",
      "423\n",
      "9287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7755, 5078],\n",
       "       [ 423, 9287]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata.head()\n",
    "#col_list=['dst_host_diff_srv_rate','dst_host_serror_rate','serror_rate','dst_host_same_src_port_rate','S0','dst_host_srv_serror_rate','class']\n",
    "#col_list=['class','ecr_i','src_bytes','http','dst_bytes','count','private','dst_host_srv_count','dst_host_same_srv_rate','dst_host_same_src_port_rate','hot','dst_host_srv_serror_rate','is_guest_login','icmp','REJ','dst_host_serror_rate','dst_host_srv_diff_host_rate','tcp','urp_i','dst_host_rerror_rate','finger']\n",
    "#col_list=['class','ecr_i','src_bytes','http','dst_bytes','count','private','dst_host_srv_count','dst_host_same_srv_rate','dst_host_same_src_port_rate','hot']\n",
    "#col_list=['class','ecr_i','src_bytes','http','dst_bytes','count']\n",
    "\n",
    "\n",
    "#10 feature set\n",
    "#col_list=['class','src_bytes', 'dst_bytes','hot','count','dst_host_srv_count','dst_host_same_srv_rate','dst_host_same_src_port_rate','ecr_i','http','private']\n",
    "\n",
    "#8 feature set\n",
    "#col_list=['class','src_bytes', 'dst_bytes','hot','count','dst_host_same_srv_rate','ecr_i','http','private']\n",
    "\n",
    "#6 feature set\n",
    "col_list=['class','src_bytes', 'dst_bytes','hot','count','ecr_i','http']\n",
    "\n",
    "#4 feature set\n",
    "#col_list=['class','src_bytes', 'dst_bytes','ecr_i','http']\n",
    "\n",
    "#3 feature set\n",
    "#col_list=['class','src_bytes', 'ecr_i','http']\n",
    "\n",
    "#col_list=['class','ecr_i','http','src_bytes','hot','dst_bytes','dst_host_same_srv_rate']\n",
    "alldata2=alldata[col_list]\n",
    "traindata=alldata2.ix[0:trainlen-1,:]\n",
    "testdata=alldata2.ix[trainlen:alldata2.shape[0],:]\n",
    "\n",
    "\n",
    "#X = traindata.iloc[:,1:42]\n",
    "#Y = traindata.iloc[:,0]\n",
    "#C = testdata.iloc[:,0]\n",
    "#T = testdata.iloc[:,1:42]\n",
    "\n",
    "X = traindata.drop('class', axis=1)\n",
    "Y = traindata[['class']]\n",
    "T = testdata.drop('class',axis=1)\n",
    "C = testdata[['class']]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "# summarize transformed data\n",
    "np.set_printoptions(precision=3)\n",
    "#print(trainX[0:5,:])\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "# summarize transformed data\n",
    "np.set_printoptions(precision=3)\n",
    "#print(testT[0:5,:])\n",
    "\n",
    "print(\"X info\")\n",
    "X.info()\n",
    "print(\"Y info\")\n",
    "Y.info()\n",
    "print(\"T info\")\n",
    "T.info()\n",
    "print(\"C info\")\n",
    "C.info()\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X.columns)\n",
    "print(T.columns)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "#model = Sequential()\n",
    "#model.add(LSTM(4,input_dim=(1,122)))  # try using a GRU instead, for fun\n",
    "\n",
    "\n",
    "\n",
    "# configure network\n",
    "print(\"TIME BEGIN:\",datetime.datetime.now())\n",
    "n_epoch = 100\n",
    "n_neurons = 80\n",
    "# design network\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(LSTM(n_neurons,input_shape=(1,6)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "#print(model.get_config())\n",
    "\n",
    "\n",
    "#model = Sequential([\n",
    "#    LSTM(4,input_shape=(1,122)),\n",
    "#    Dense(len(class_names), activation='softmax')\n",
    "#])\n",
    "\n",
    "#model.compile(\n",
    "#    optimizer='adam',\n",
    "#    loss='sparse_categorical_crossentropy',\n",
    "#    metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "sgd = optimizers.SGD(lr=0.5)\n",
    "model.compile(loss='binary_crossentropy',optimizer=sgd,metrics=['accuracy'])\n",
    "#model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "#checkpointer = callbacks.ModelCheckpoint(filepath=\"kddresults/lstm1layer/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('6featuresetlog.csv',separator=',', append=False)\n",
    "#model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=1000, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=45, validation_data=(X_test, y_test),callbacks=[csv_logger])\n",
    "\n",
    "#model.save(\"kddresults/lstm1layer/fullmodel/lstm1layer_model.hdf5\")\n",
    "# Save the model\n",
    "model.save('6featureModel.h5')\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "#np.savetxt('kddresults/lstm1layer/lstm1predicted.txt', y_pred, fmt='%01d')\n",
    "\n",
    "print(\"TIME END:\",datetime.datetime.now())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
    "print(tn)\n",
    "print(fp)\n",
    "print(fn)\n",
    "print(tp)\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7715057113187955"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(y_test, y_pred, labels=np.unique(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "/home/dsu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1001 15:47:23.960289 140350102923072 deprecation_wrapper.py:119] From /home/dsu/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1001 15:47:23.964316 140350102923072 deprecation_wrapper.py:119] From /home/dsu/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:504: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1001 15:47:23.969334 140350102923072 deprecation_wrapper.py:119] From /home/dsu/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3828: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Data columns (total 8 columns):\n",
      "src_bytes                 125973 non-null int64\n",
      "dst_bytes                 125973 non-null int64\n",
      "hot                       125973 non-null int64\n",
      "count                     125973 non-null int64\n",
      "dst_host_same_srv_rate    125973 non-null float64\n",
      "ecr_i                     125973 non-null uint8\n",
      "http                      125973 non-null uint8\n",
      "private                   125973 non-null uint8\n",
      "dtypes: float64(1), int64(4), uint8(3)\n",
      "memory usage: 5.2 MB\n",
      "Y info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Data columns (total 1 columns):\n",
      "class    125973 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 984.2 KB\n",
      "T info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22543 entries, 125973 to 148515\n",
      "Data columns (total 8 columns):\n",
      "src_bytes                 22543 non-null int64\n",
      "dst_bytes                 22543 non-null int64\n",
      "hot                       22543 non-null int64\n",
      "count                     22543 non-null int64\n",
      "dst_host_same_srv_rate    22543 non-null float64\n",
      "ecr_i                     22543 non-null uint8\n",
      "http                      22543 non-null uint8\n",
      "private                   22543 non-null uint8\n",
      "dtypes: float64(1), int64(4), uint8(3)\n",
      "memory usage: 946.7 KB\n",
      "C info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22543 entries, 125973 to 148515\n",
      "Data columns (total 1 columns):\n",
      "class    22543 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 176.2 KB\n",
      "(125973, 1, 8)\n",
      "(22543, 1, 8)\n",
      "Index(['src_bytes', 'dst_bytes', 'hot', 'count', 'dst_host_same_srv_rate',\n",
      "       'ecr_i', 'http', 'private'],\n",
      "      dtype='object')\n",
      "Index(['src_bytes', 'dst_bytes', 'hot', 'count', 'dst_host_same_srv_rate',\n",
      "       'ecr_i', 'http', 'private'],\n",
      "      dtype='object')\n",
      "TIME BEGIN: 2019-10-01 15:47:23.959222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1001 15:47:24.143772 140350102923072 deprecation_wrapper.py:119] From /home/dsu/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:126: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1001 15:47:24.149924 140350102923072 deprecation.py:506] From /home/dsu/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3135: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1001 15:47:24.185242 140350102923072 deprecation_wrapper.py:119] From /home/dsu/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:744: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1001 15:47:24.189196 140350102923072 deprecation_wrapper.py:119] From /home/dsu/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3066: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1001 15:47:24.192377 140350102923072 deprecation.py:323] From /home/dsu/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 125973 samples, validate on 22543 samples\n",
      "Epoch 1/45\n",
      "125973/125973 [==============================] - 50s 397us/step - loss: 0.1746 - acc: 0.9247 - val_loss: 0.8836 - val_acc: 0.7479\n",
      "Epoch 2/45\n",
      "125973/125973 [==============================] - 47s 373us/step - loss: 0.1470 - acc: 0.9454 - val_loss: 0.9539 - val_acc: 0.7208\n",
      "Epoch 3/45\n",
      "125973/125973 [==============================] - 47s 377us/step - loss: 0.1366 - acc: 0.9564 - val_loss: 0.8962 - val_acc: 0.7320\n",
      "Epoch 4/45\n",
      "125973/125973 [==============================] - 47s 372us/step - loss: 0.1277 - acc: 0.9595 - val_loss: 0.8905 - val_acc: 0.7326\n",
      "Epoch 5/45\n",
      "125973/125973 [==============================] - 47s 375us/step - loss: 0.1226 - acc: 0.9603 - val_loss: 0.8310 - val_acc: 0.7453\n",
      "Epoch 6/45\n",
      "125973/125973 [==============================] - 47s 373us/step - loss: 0.1200 - acc: 0.9610 - val_loss: 0.9401 - val_acc: 0.7350\n",
      "Epoch 7/45\n",
      "125973/125973 [==============================] - 47s 375us/step - loss: 0.1188 - acc: 0.9614 - val_loss: 0.8763 - val_acc: 0.7487\n",
      "Epoch 8/45\n",
      "125973/125973 [==============================] - 47s 373us/step - loss: 0.1177 - acc: 0.9612 - val_loss: 0.8726 - val_acc: 0.7466\n",
      "Epoch 9/45\n",
      "125973/125973 [==============================] - 46s 369us/step - loss: 0.1168 - acc: 0.9613 - val_loss: 0.9354 - val_acc: 0.7292\n",
      "Epoch 10/45\n",
      "125973/125973 [==============================] - 47s 377us/step - loss: 0.1161 - acc: 0.9610 - val_loss: 0.8142 - val_acc: 0.7503\n",
      "Epoch 11/45\n",
      "125973/125973 [==============================] - 48s 378us/step - loss: 0.1160 - acc: 0.9612 - val_loss: 0.9096 - val_acc: 0.7361\n",
      "Epoch 12/45\n",
      "125973/125973 [==============================] - 47s 375us/step - loss: 0.1155 - acc: 0.9613 - val_loss: 0.9000 - val_acc: 0.7348\n",
      "Epoch 13/45\n",
      "125973/125973 [==============================] - 47s 370us/step - loss: 0.1153 - acc: 0.9610 - val_loss: 0.9523 - val_acc: 0.7326\n",
      "Epoch 14/45\n",
      "125973/125973 [==============================] - 47s 370us/step - loss: 0.1149 - acc: 0.9614 - val_loss: 0.8861 - val_acc: 0.7395\n",
      "Epoch 15/45\n",
      "125973/125973 [==============================] - 47s 375us/step - loss: 0.1145 - acc: 0.9616 - val_loss: 0.9145 - val_acc: 0.7385\n",
      "Epoch 16/45\n",
      "125973/125973 [==============================] - 48s 378us/step - loss: 0.1134 - acc: 0.9614 - val_loss: 0.9244 - val_acc: 0.7447\n",
      "Epoch 17/45\n",
      "125973/125973 [==============================] - 47s 372us/step - loss: 0.1133 - acc: 0.9615 - val_loss: 0.8796 - val_acc: 0.7432\n",
      "Epoch 18/45\n",
      "125973/125973 [==============================] - 47s 372us/step - loss: 0.1128 - acc: 0.9615 - val_loss: 0.8610 - val_acc: 0.7535\n",
      "Epoch 19/45\n",
      "125973/125973 [==============================] - 47s 374us/step - loss: 0.1126 - acc: 0.9613 - val_loss: 0.8684 - val_acc: 0.7534\n",
      "Epoch 20/45\n",
      "125973/125973 [==============================] - 47s 371us/step - loss: 0.1126 - acc: 0.9613 - val_loss: 0.8989 - val_acc: 0.7309\n",
      "Epoch 21/45\n",
      "125973/125973 [==============================] - 47s 371us/step - loss: 0.1124 - acc: 0.9613 - val_loss: 0.7801 - val_acc: 0.7524\n",
      "Epoch 22/45\n",
      "125973/125973 [==============================] - 46s 368us/step - loss: 0.1122 - acc: 0.9614 - val_loss: 0.9398 - val_acc: 0.7300\n",
      "Epoch 23/45\n",
      "125973/125973 [==============================] - 46s 369us/step - loss: 0.1115 - acc: 0.9612 - val_loss: 0.8590 - val_acc: 0.7436\n",
      "Epoch 24/45\n",
      "125973/125973 [==============================] - 47s 375us/step - loss: 0.1112 - acc: 0.9614 - val_loss: 0.8328 - val_acc: 0.7542\n",
      "Epoch 25/45\n",
      "125973/125973 [==============================] - 47s 372us/step - loss: 0.1109 - acc: 0.9616 - val_loss: 0.9101 - val_acc: 0.7355\n",
      "Epoch 26/45\n",
      "125973/125973 [==============================] - 47s 374us/step - loss: 0.1111 - acc: 0.9615 - val_loss: 0.9047 - val_acc: 0.7365\n",
      "Epoch 27/45\n",
      "125973/125973 [==============================] - 46s 369us/step - loss: 0.1107 - acc: 0.9616 - val_loss: 0.8754 - val_acc: 0.7370\n",
      "Epoch 28/45\n",
      "125973/125973 [==============================] - 47s 370us/step - loss: 0.1101 - acc: 0.9616 - val_loss: 0.8809 - val_acc: 0.7387\n",
      "Epoch 29/45\n",
      "125973/125973 [==============================] - 47s 370us/step - loss: 0.1102 - acc: 0.9619 - val_loss: 0.9820 - val_acc: 0.7249\n",
      "Epoch 30/45\n",
      "125973/125973 [==============================] - 47s 376us/step - loss: 0.1095 - acc: 0.9618 - val_loss: 0.9334 - val_acc: 0.7356\n",
      "Epoch 31/45\n",
      "125973/125973 [==============================] - 47s 371us/step - loss: 0.1094 - acc: 0.9617 - val_loss: 0.9149 - val_acc: 0.7339\n",
      "Epoch 32/45\n",
      "125973/125973 [==============================] - 47s 373us/step - loss: 0.1087 - acc: 0.9618 - val_loss: 0.9468 - val_acc: 0.7356\n",
      "Epoch 33/45\n",
      "125973/125973 [==============================] - 47s 373us/step - loss: 0.1080 - acc: 0.9619 - val_loss: 0.8951 - val_acc: 0.7406\n",
      "Epoch 34/45\n",
      "125973/125973 [==============================] - 47s 369us/step - loss: 0.1084 - acc: 0.9620 - val_loss: 0.8769 - val_acc: 0.7454\n",
      "Epoch 35/45\n",
      "125973/125973 [==============================] - 47s 372us/step - loss: 0.1078 - acc: 0.9617 - val_loss: 0.8912 - val_acc: 0.7360\n",
      "Epoch 36/45\n",
      "125973/125973 [==============================] - 47s 376us/step - loss: 0.1072 - acc: 0.9622 - val_loss: 0.8461 - val_acc: 0.7493\n",
      "Epoch 37/45\n",
      "125973/125973 [==============================] - 47s 373us/step - loss: 0.1061 - acc: 0.9621 - val_loss: 0.9575 - val_acc: 0.7252\n",
      "Epoch 38/45\n",
      "125973/125973 [==============================] - 47s 374us/step - loss: 0.1055 - acc: 0.9622 - val_loss: 0.9077 - val_acc: 0.7320\n",
      "Epoch 39/45\n",
      "125973/125973 [==============================] - 47s 372us/step - loss: 0.1055 - acc: 0.9625 - val_loss: 0.8409 - val_acc: 0.7464\n",
      "Epoch 40/45\n",
      "125973/125973 [==============================] - 47s 375us/step - loss: 0.1049 - acc: 0.9625 - val_loss: 0.8978 - val_acc: 0.7409\n",
      "Epoch 41/45\n",
      "125973/125973 [==============================] - 47s 370us/step - loss: 0.1047 - acc: 0.9628 - val_loss: 0.8218 - val_acc: 0.7487\n",
      "Epoch 42/45\n",
      "125973/125973 [==============================] - 48s 378us/step - loss: 0.1046 - acc: 0.9628 - val_loss: 0.8802 - val_acc: 0.7431\n",
      "Epoch 43/45\n",
      "125973/125973 [==============================] - 47s 371us/step - loss: 0.1041 - acc: 0.9628 - val_loss: 0.9210 - val_acc: 0.7295\n",
      "Epoch 44/45\n",
      "125973/125973 [==============================] - 47s 373us/step - loss: 0.1041 - acc: 0.9624 - val_loss: 0.8614 - val_acc: 0.7393\n",
      "Epoch 45/45\n",
      "125973/125973 [==============================] - 47s 373us/step - loss: 0.1038 - acc: 0.9627 - val_loss: 0.8601 - val_acc: 0.7382\n",
      "22543/22543 [==============================] - 3s 114us/step\n",
      "\n",
      "Loss: 0.86, Accuracy: 73.82%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.57      0.71     12833\n",
      "           1       0.63      0.97      0.76      9710\n",
      "\n",
      "    accuracy                           0.74     22543\n",
      "   macro avg       0.79      0.77      0.74     22543\n",
      "weighted avg       0.81      0.74      0.73     22543\n",
      "\n",
      "TIME END: 2019-10-01 16:22:46.529195\n",
      "7267\n",
      "5566\n",
      "335\n",
      "9375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7267, 5566],\n",
       "       [ 335, 9375]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata.head()\n",
    "#col_list=['dst_host_diff_srv_rate','dst_host_serror_rate','serror_rate','dst_host_same_src_port_rate','S0','dst_host_srv_serror_rate','class']\n",
    "#col_list=['class','ecr_i','src_bytes','http','dst_bytes','count','private','dst_host_srv_count','dst_host_same_srv_rate','dst_host_same_src_port_rate','hot','dst_host_srv_serror_rate','is_guest_login','icmp','REJ','dst_host_serror_rate','dst_host_srv_diff_host_rate','tcp','urp_i','dst_host_rerror_rate','finger']\n",
    "#col_list=['class','ecr_i','src_bytes','http','dst_bytes','count','private','dst_host_srv_count','dst_host_same_srv_rate','dst_host_same_src_port_rate','hot']\n",
    "#col_list=['class','ecr_i','src_bytes','http','dst_bytes','count']\n",
    "\n",
    "\n",
    "#10 feature set\n",
    "#col_list=['class','src_bytes', 'dst_bytes','hot','count','dst_host_srv_count','dst_host_same_srv_rate','dst_host_same_src_port_rate','ecr_i','http','private']\n",
    "\n",
    "#8 feature set\n",
    "col_list=['class','src_bytes', 'dst_bytes','hot','count','dst_host_same_srv_rate','ecr_i','http','private']\n",
    "\n",
    "#6 feature set\n",
    "#col_list=['class','src_bytes', 'dst_bytes','hot','count','ecr_i','http']\n",
    "\n",
    "#4 feature set\n",
    "#col_list=['class','src_bytes', 'dst_bytes','ecr_i','http']\n",
    "\n",
    "#3 feature set\n",
    "#col_list=['class','src_bytes', 'ecr_i','http']\n",
    "\n",
    "#col_list=['class','ecr_i','http','src_bytes','hot','dst_bytes','dst_host_same_srv_rate']\n",
    "alldata2=alldata[col_list]\n",
    "traindata=alldata2.ix[0:trainlen-1,:]\n",
    "testdata=alldata2.ix[trainlen:alldata2.shape[0],:]\n",
    "\n",
    "\n",
    "#X = traindata.iloc[:,1:42]\n",
    "#Y = traindata.iloc[:,0]\n",
    "#C = testdata.iloc[:,0]\n",
    "#T = testdata.iloc[:,1:42]\n",
    "\n",
    "X = traindata.drop('class', axis=1)\n",
    "Y = traindata[['class']]\n",
    "T = testdata.drop('class',axis=1)\n",
    "C = testdata[['class']]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "# summarize transformed data\n",
    "np.set_printoptions(precision=3)\n",
    "#print(trainX[0:5,:])\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "# summarize transformed data\n",
    "np.set_printoptions(precision=3)\n",
    "#print(testT[0:5,:])\n",
    "\n",
    "print(\"X info\")\n",
    "X.info()\n",
    "print(\"Y info\")\n",
    "Y.info()\n",
    "print(\"T info\")\n",
    "T.info()\n",
    "print(\"C info\")\n",
    "C.info()\n",
    "y_train = np.array(Y)\n",
    "y_test = np.array(C)\n",
    "\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "X_test = np.reshape(testT, (testT.shape[0], 1, testT.shape[1]))\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X.columns)\n",
    "print(T.columns)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 1. define the network\n",
    "#model = Sequential()\n",
    "#model.add(LSTM(4,input_dim=(1,122)))  # try using a GRU instead, for fun\n",
    "\n",
    "\n",
    "\n",
    "# configure network\n",
    "print(\"TIME BEGIN:\",datetime.datetime.now())\n",
    "n_epoch = 100\n",
    "n_neurons = 80\n",
    "# design network\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(LSTM(n_neurons,input_shape=(1,8)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "#print(model.get_config())\n",
    "\n",
    "\n",
    "#model = Sequential([\n",
    "#    LSTM(4,input_shape=(1,122)),\n",
    "#    Dense(len(class_names), activation='softmax')\n",
    "#])\n",
    "\n",
    "#model.compile(\n",
    "#    optimizer='adam',\n",
    "#    loss='sparse_categorical_crossentropy',\n",
    "#    metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "sgd = optimizers.SGD(lr=0.5)\n",
    "model.compile(loss='binary_crossentropy',optimizer=sgd,metrics=['accuracy'])\n",
    "#model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "#checkpointer = callbacks.ModelCheckpoint(filepath=\"kddresults/lstm1layer/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "csv_logger = CSVLogger('8featuresetlog.csv',separator=',', append=False)\n",
    "#model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=1000, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=45, validation_data=(X_test, y_test),callbacks=[csv_logger])\n",
    "\n",
    "#model.save(\"kddresults/lstm1layer/fullmodel/lstm1layer_model.hdf5\")\n",
    "# Save the model\n",
    "model.save('8featureModel.h5')\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "#np.savetxt('kddresults/lstm1layer/lstm1predicted.txt', y_pred, fmt='%01d')\n",
    "\n",
    "print(\"TIME END:\",datetime.datetime.now())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
    "print(tn)\n",
    "print(fp)\n",
    "print(fn)\n",
    "print(tp)\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7606182304977485"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(y_test, y_pred, labels=np.unique(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
